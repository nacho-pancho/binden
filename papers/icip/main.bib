@INPROCEEDINGS{bm3d,
  author={Dabov, K. and Foi, A. and Katkovnik, V. and Egiazarian, K.},
  booktitle={2007 IEEE Intl. Conf. on Image Proc.}, 
  title={Color Image Denoising via Sparse 3D Collaborative Filtering with Grouping Constraint in Luminance-Chrominance Space}, 
  year={2007},
  volume={1},
  number={},
  pages={I - 313-I - 316},
  doi={10.1109/ICIP.2007.4378954}}


@INPROCEEDINGS{epll,
  author={Zoran, D. and Weiss, Y.},
  booktitle={2011 Intl. Conf. on Comp. Vision}, 
  title={From learning models of natural image patches to whole image restoration}, 
  year={2011},
  volume={},
  number={},
  pages={479-486},
  doi={10.1109/ICCV.2011.6126278}}
  
@INPROCEEDINGS{nlm,  author={Buades, A. and Coll, B. and Morel, J.-M.},  booktitle={2005 IEEE Computer Society Conf. on Comp. Vision and Pat. Rec. (CVPR'05)},   title={A non-local algorithm for image denoising},   year={2005},  volume={2},  number={},  pages={60-65 vol. 2},  doi={10.1109/CVPR.2005.38}}

@article{nlbayes,
author = {Lebrun, M. and Buades, A. and Morel, J. M.},
title = {A Nonlocal Bayesian Image Denoising Algorithm},
journal = {SIAM Journal on Imaging Sciences},
volume = {6},
number = {3},
pages = {1665-1688},
year = {2013},
doi = {10.1137/120874989},
URL = { https://doi.org/10.1137/120874989},
eprint = {https://doi.org/10.1137/120874989}
}

@inproceedings{luisa,
title={A computational framework for the analysis of the Uruguayan dictatorship archives},
COMMENTauthor={L. Etcheverry and L. Agorio and V. Bacigalupe and Sofía Barreiro and Elena Bing and Samuel Blixen and Daniel Calegari and Lautaro Cardozo and Fernando Carpani and Felipe Chavat and Diego Garat and Alvaro Gomez and Fabián Hernández and Victor Marabotto and Guillermo Moncecchi and Ignacio Ramírez and Aiala Rosá and Jorge Tiscornia and Dina Wonsever and Gregory Randall and Guillermo Zorron and Lia Rivero and Nilo Patiño and Javier Stabile and Ernesto Fernandez and Federico Fioritto and Rodrigo Laguna},
author={L. Etcheverry et al.},
booktitle={Proceedings of the Conference on Digital Curation Technologies (Qurator 2021)
Berlin, Germany}, 
month={Feb.},
year={2021}
}

@ARTICLE{mcmc-denoising,
author={Jalali, S. and Weissman, T.},
journal={IEEE Transactions on Signal Processing}, title={Denoising via MCMC-Based Lossy Compression},
year={2012},
volume={60},
number={6},
pages={3092-3100},
abstract={It has been established in the literature, in various theoretical and asymptotic senses, that universal lossy compression followed by some simple postprocessing results in universal denoising, for the setting of a stationary ergodic source corrupted by additive white noise. However, this interesting theoretical result has not yet been tested in practice in denoising simulated or real data. In this paper, we employ a recently developed MCMC-based universal lossy compressor to build a universal compression-based denoising algorithm. We show that applying this iterative lossy compression algorithm with appropriately chosen distortion measure and distortion level, followed by a simple derandomization operation, results in a family of denoisers that compares favorably (both theoretically and in practice) with other MCMC-based schemes, and with the discrete universal denoiser DUDE.},
keywords={Noise reduction;Noise;Distortion measurement;Vectors;Markov processes;Loss measurement;Simulated annealing;Compression-based denoising;denoising;Markov chain Monte Carlo;simulated annealing;universal lossy compression},
doi={10.1109/TSP.2012.2190597},
ISSN={1941-0476},
month={June},}
@INPROCEEDINGS{5513338,
author={Su, Han-I and Weissman, Tsachy},
booktitle={2010 IEEE International Symposium on Information Theory}, title={Universal lossless compression-based denoising},
year={2010},
volume={},
number={},
pages={1648-1652},
abstract={In a discrete denoising problem, if the denoiser knows the clean source distribution, the Bayes optimal denoiser is the Bayes response of the posterior distribution of the source given the noisy observations. However, in many applications the source distribution is unknown.We consider the Bayes response based on the approximate posterior distribution induced by a universal lossless compression code. Motivated by this approach, we present the empirical conditional entropy-based denoiser. Simulations show that when the source alphabet is small, the proposed denoiser achieves the performance of the Universal Discrete DEnoiser (DUDE). Furthermore, if the alphabet size increases, the proposed denoiser degrades more gracefully than the DUDE.},
keywords={Noise reduction;Hidden Markov models;Nonlinear filters;Markov processes;Filtering;Computational complexity;Degradation;Performance loss;Loss measurement;Maximum likelihood detection},
doi={10.1109/ISIT.2010.5513338},
ISSN={2157-8117},
month={June},}


@ARTICLE{shift-denoising,
author={Moon, T. and Weissman, T.},
journal={IEEE Transactions on Information Theory}, title={Discrete Denoising With Shifts},
year={2009},
volume={55},
number={11},
pages={5284-5301},
abstract={We introduce S-DUDE, a new algorithm for denoising discrete memoryless channel (DMC)-corrupted data. The algorithm, which generalizes the recently introduced DUDE (discrete universal denoiser), aims to compete with a genie that has access, in addition to the noisy data, also to the underlying clean data, and that can choose to switch, up to m times, between sliding-window denoisers in a way that minimizes the overall loss. When the underlying data form an individual sequence, we show that the S-DUDE performs essentially as well as this genie, provided that m is sublinear in the size of the data. When the clean data are emitted by a piecewise stationary process, we show that the S-DUDE achieves the optimum distribution-dependent performance, provided that the same sublinearity condition is imposed on the number of switches. To further substantiate the universal optimality of the S-DUDE, we show that when the number of switches is allowed to grow linearly with the size of the data, any (sequence of) scheme(s) fails to compete in the above sense. Using dynamic programming, we derive an efficient implementation of the S-DUDE, which has complexity (time and memory) growing linearly with the data size and the number of switches m . Preliminary experimental results are presented, suggesting that S-DUDE has the capacity to improve on the performance attained by the original DUDE in applications where the nature of the data abruptly changes in time (or space), as is often the case in practice.},
keywords={Noise reduction;Switches;Moon;Memoryless systems;Dynamic programming;Algorithm design and analysis;Scholarships;Communication system control;Cities and towns;Colored noise;Competitive analysis;discrete denoising;discrete memoryless channel (DMC);dynamic programming;forward-backward recursions;individual sequence;piecewise stationary processes;switching experts;universal algorithms},
doi={10.1109/TIT.2009.2030461},
ISSN={1557-9654},
month={Nov},}



@INPROCEEDINGS{compression-denoising,
author={Jalali, S. and Weissman, T.},
booktitle={2008 42nd Annual Conference on Information Sciences and Systems}, title={Near optimal lossy source coding and compression-based denoising via Markov chain Monte Carlo},
year={2008},
volume={},
number={},
pages={441-446},
abstract={We propose an implementable new universal lossy source coding algorithm. The new algorithm utilizes two well- known tools from statistical physics and computer science: Gibbs sampling and simulated annealing. In order to code a source sequence xn, the encoder initializes the reconstruction block as xn = xn, and then at each iteration uniformly at random chooses one of the symbols of xn, and updates it. This updating is based on some conditional probability distribution which depends on a parameter beta representing inverse temperature, an integer parameter k = o(logn) representing context length, and the original source sequence. At the end of this process, the encoder outputs the Lempel-Ziv description of xn, which the decoder deciphers perfectly, and sets as its reconstruction. The complexity of the proposed algorithm in each iteration is linear in k and independent of n. We prove that, for any stationary ergodic source, the algorithm achieves the optimal rate-distortion performance asymptotically in the limits of large number of iterations, beta, and n. We also show how our approach carries over to such problems as universal Wyner-Ziv coding and compression-based denoising.},
keywords={Source coding;Noise reduction;Monte Carlo methods;Physics;Computer science;Sampling methods;Computational modeling;Computer simulation;Simulated annealing;Probability distribution},
doi={10.1109/CISS.2008.4558567},
ISSN={},
month={March},}

@ARTICLE{minimax-denoising,
author={Gemelos, G.M. and Sigurjonsson, S. and Weissman, T.},
journal={IEEE Transactions on Information Theory}, title={Universal Minimax Discrete Denoising Under Channel Uncertainty},
year={2006},
volume={52},
number={8},
pages={3476-3497},
abstract={The goal of a denoising algorithm is to recover a signal from its noise-corrupted observations. Perfect recovery is seldom possible and performance is measured under a given single-letter fidelity criterion. For discrete signals corrupted by a known discrete memoryless channel (DMC), the Discrete Universal DEnoiser (DUDE) was recently shown to perform this task asymptotically optimally, without knowledge of the statistical properties of the source. In the present work, we address the scenario where, in addition to the lack of knowledge of the source statistics, there is also uncertainty in the channel characteristics. We propose a family of discrete denoisers and establish their asymptotic optimality under a minimax performance criterion which we argue is appropriate for this setting. As we show elsewhere, the proposed schemes can also be implemented computationally efficiently},
keywords={Minimax techniques;Noise reduction;Uncertainty;Humans;Feedback;Image reconstruction;Statistics;Monte Carlo methods;Information theory;Memoryless systems;Denoising;denoising algorithms;discrete universal denoising;Discrete Universal DEnoiser (DUDE);estimation;minimax schemes},
doi={10.1109/TIT.2006.878234},
ISSN={1557-9654},
month={Aug},}


@ARTICLE{lambda-denoising,
author={Li, L. and Ge, H. and Zhang, Y. and Gao, J.},
title={Low-density noise removal based on lambda multi-diagonal matrix filter for binary image},
journal={Neural Computing and Applications},
year={2018},
volume={29},
number={6},
pages={173-185},
doi={10.1007/s00521-016-2538-7},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84982242327&doi=10.1007%2fs00521-016-2538-7&partnerID=40&md5=cacc0626e2732242ebf45d7ec62498a2},
abstract={Binary image denoising is a well-known problem, and it is the concern of diverse application areas. Many classical denoising techniques have evolved over the years, such as mean filter, median filter, and morphological filter. A new denoising method based on the multiplication of lambda multi-diagonal binary matrix (λ-MDBM) is proposed for binary images in this paper. In proposed method, first the users need to choose an appropriate lambda value from the set { λ| λ∈ [ 0.5 , 1 ] } , and then the hybrid noisy binary image matrix can be obtained by adding the noisy binary image matrix times the λ-MDBM and the transpose of the noisy binary image matrix times the λ-MDBM, and finally the de-noised binary image can be obtained by a preset threshold. The experimental results show that a new denoising method based on λ-MDBM is possible in peak signal-to-noise ratio and mean square error. © 2016, The Natural Computing Applications Forum.},
author_keywords={Binary image processing;  Filtering;  Image denoising;  Lambda multi-diagonal matrix filter},
keywords={Bandpass filters;  Binary images;  Bins;  Filtration;  Image processing;  Matrix algebra;  Mean square error;  Median filters;  Signal to noise ratio, Binary matrix;  De-noising techniques;  Denoising methods;  Diagonal matrices;  Diverse applications;  Morphological filters;  Noise removal;  Peak signal to noise ratio, Image denoising},
document_type={Article},
source={Scopus},
}

@ARTICLE{altmin-denoising,
author={Zhang, J.},
title={An alternating minimization algorithm for binary image restoration},
journal={IEEE Transactions on Image Processing},
year={2012},
volume={21},
number={2},
pages={883-888},
doi={10.1109/TIP.2011.2162426},
art_number={5957297},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863052811&doi=10.1109%2fTIP.2011.2162426&partnerID=40&md5=f19ab05aec1403981a325c2d54e34d5c},
abstract={The problem we will consider in this paper is binary image restoration. It is, in essence, difficult to solve because of the combinatorial nature of the problem. To overcome this difficulty, we propose a new minimization model by making use of a new variable to enforce the image to be binary. Based on the proposed minimization model, we present a fast alternating minimization algorithm for binary image restoration. We prove the convergence of the proposed alternating minimization algorithm. Experimental results show that the proposed method is feasible and effective for binary image restoration. © 2011 IEEE.},
author_keywords={Blur;  fast Fourier transform (FFT);  Gaussian noise;  image restoration;  iterative algorithm;  regularization},
keywords={Alternating minimization algorithms;  Blur;  Iterative algorithm;  regularization, Binary images;  Fast Fourier transforms;  Gaussian noise (electronic);  Image reconstruction;  Restoration, Algorithms},
document_type={Article},
source={Scopus},
}

@CONFERENCE{horrible-denoising,
author={Mulyana, T.M.S.},
title={Reduce noise in the binary image using non linear spatial filtering of mode},
journal={Proceedings of 2016 International Conference on Information and Communication Technology and Systems, ICTS 2016},
year={2017},
pages={135-139},
doi={10.1109/ICTS.2016.7910287},
art_number={7910287},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019408492&doi=10.1109%2fICTS.2016.7910287&partnerID=40&md5=d575210fb2a887dcaeec704c778f56b1},
abstract={Noise is a problem that is often encountered when separating the object from the background in the binary image. Noise may occur in the background and the object, can be spot or patchy and the tassel is connected to the object. The research segmentation of pupil object from eye image, tries to using non-linear spatial filtering of mode to reduce noise in the binary image. Using this filtering at the binary image, can be reduced the both of black noise at the background and the white noise at the object image. Also reduce spot noise and tassel noise. © 2016 IEEE.},
author_keywords={binary image;  noise reduction;  non-linear spatial filtering of mode},
keywords={Beamforming;  Bins;  Image denoising;  Image segmentation;  Noise abatement;  White noise, Eye images;  Non linear;  Spatial filterings, Binary images},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{binden-comparison,
author={Rani, U. and Kaur, A. and Josan, G.},
title={Comparative Analysis of Salt and Pepper Removal Techniques for Binary Images},
journal={Advances in Intelligent Systems and Computing},
year={2020},
volume={1082},
pages={377-389},
doi={10.1007/978-981-15-1081-6_32},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081159621&doi=10.1007%2f978-981-15-1081-6_32&partnerID=40&md5=3d1ea70ad9b8020a1bb798485d183b41},
abstract={Binarization is the most important step in the OCR system that converts the gray level or colored images into bi-level form. In the case of degraded images, results after binarization mostly contain noises. Salt and pepper noise of different sizes is the most prevalent noise in binary images. For the better results of OCR process, it is necessary to denoise image before proceeding to the next stage. This paper conducts experiments with different existing salt and pepper noise removal methods such as median filter-based techniques and kFill algorithm-based techniques for binary document images. The statistical measures, namely, PSNR, SSIM, and EPI are used to evaluate the performance. © 2020, Springer Nature Singapore Pte Ltd.},
author_keywords={Degraded documents;  kFill filter;  Median filter;  Salt and pepper noise},
keywords={Binary images;  Intelligent computing;  Median filters;  Optical character recognition;  Salt removal, Binary document image;  Comparative analysis;  Degraded documents;  kFill filter;  Salt and peppers;  Salt-and-pepper noise;  Salt-and-pepper noise removal;  Statistical measures, Image denoising},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{nlm-binary-patterns,
author={Kartsov, S.K. and Kupriyanov, D.Y. and Polyakov, Y.A. and Zykov, A.N.},
title={Non-local Means Denoising Algorithm Based on Local Binary Patterns},
journal={Intelligent Systems Reference Library},
year={2020},
volume={182},
pages={153-164},
doi={10.1007/978-3-030-39177-5_12},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079370845&doi=10.1007%2f978-3-030-39177-5_12&partnerID=40&md5=e31e144c48a9dc8e791259e2a56e60cc},
abstract={Previously, the document flow was mainly through the using of documents in paper form. It created the series of problems during the archiving and searching of the necessary documents. The archive paper documents take a lot of noise points, therefore it is the problem to search of documents in the archive, because there are mistakes in documents, and searching requires a long time. While information technology, it became possible using scanners to convert documents from paper to electronic form. In the process of scanning and due to the fact, that the documents are not always in good shape, the output images are obtained with various defects in the form of noise. Various noise reduction algorithms are used to improve the image quality and remove the noise from scanned documents. This chapter discusses a possibility of using Local Binary Patterns (LBP) operator to make changes into the operation of Non-Local Means (NLM) noise reduction algorithm. As a result, it was possible to improve a quality of scanned images after their processing by the proposed modified algorithm. © 2020, Springer Nature Switzerland AG.},
author_keywords={Algorithm image denoising;  Digital image processing;  Local binary patterns operator;  Noise reduction;  Non-local means},
document_type={Book Chapter},
source={Scopus},
}

@CONFERENCE{graph,
author={Potts, C. and Yang, L. and Oyen, D. and Wohlberg, B.},
title={A topological graph-based representation for denoising low quality binary images},
journal={Proceedings - 2019 International Conference on Computer Vision Workshop, ICCVW 2019},
year={2019},
pages={1788-1798},
doi={10.1109/ICCVW.2019.00222},
art_number={9022262},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082478624&doi=10.1109%2fICCVW.2019.00222&partnerID=40&md5=873ba5224a66f536d2c057d9fb3ab4ca},
abstract={Scanned images of patent or historical documents often contain localized zigzag noise introduced by the digitizing process; yet when viewed as a whole image, global structures are apparent to humans, but not to machines. Existing denoising methods work well for natural images, but not for binary diagram images, which makes feature extraction difficult for computer vision and machine learning methods and algorithms. We propose a topological graph-based representation to tackle this denoising problem. The graph representation emphasizes the shapes and topology of diagram images, making it ideal for use in machine learning applications such as classification and matching of scientific diagram images. Our approach and algorithms provide essential structure and lay important foundation for computer vision such as scene graph-based applications, because topological relations and spatial arrangement among objects in images are captured and stored in our skeleton graph. In addition, while the parameters for almost all pixel-based methods are not adaptive, our method is robust in that it only requires one parameter and it is adaptive. Experimental comparisons with existing methods show the effectiveness of our approach. © 2019 IEEE.},
author_keywords={Binary images;  Image denoising;  Image representation;  Image skeletons;  Scanned diagram images;  Topological graph},
keywords={Computer vision;  Graph algorithms;  Graph structures;  Graphic methods;  Image denoising;  Machine learning;  Musculoskeletal system;  Topology, Experimental comparison;  Image representations;  Image skeletons;  Machine learning applications;  Machine learning methods;  Scanned diagram images;  Topological graphs;  Topological relations, Binary images},
document_type={Conference Paper},
source={Scopus},
}


@CONFERENCE{fingerprints,
author={Cherrat, E.M. and Alaoui, R. and Bouzahir, H. and Jenkal, W.},
title={High density salt-and-pepper noise suppression using adaptive dual threshold decision based algorithm in fingerprint images},
journal={2017 Intelligent Systems and Computer Vision, ISCV 2017},
year={2017},
doi={10.1109/ISACV.2017.8054913},
art_number={8054913},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034645928&doi=10.1109%2fISACV.2017.8054913&partnerID=40&md5=fff6e57a06cee46fd4f1bd5d8e932bc1},
abstract={In this paper, we will propose an efficient technique using adaptive dual threshold decision based algorithm for removing of salt and pepper noise in different fingerprint images. In the first step, the recent adaptive dual threshold is applied to detect the pixels which are likely to be corrupted more efficiently. In the second step, only the corrupted pixels are replaced by the decision based algorithm value in filter window. The quality of fingerprint images denoising is studied. It is shown that the new scheme is significantly better with the peak signal to noise ratio (PSNR) when compared to some recently published method. Also, it will establish in improving performance of removing salt and pepper noise. © 2017 IEEE.},
author_keywords={adaptive dual threshold;  Fingerprint recognition system;  Image denoising;  salt and pepper noise},
keywords={Computer vision;  Intelligent systems;  Pattern recognition;  Pixels;  Signal to noise ratio, adaptive dual threshold;  Decision-based algorithms;  Filter windows;  Fingerprint images;  Fingerprint recognition systems;  Improving performance;  Peak signal to noise ratio;  Salt-and-pepper noise, Image denoising},
document_type={Conference Paper},
source={Scopus},
}


@ARTICLE{nlm-binary-descriptor,
author={Yu, H. and Li, A.},
title={Real-time non-local means image denoising algorithm based on local binary descriptor_R1},
journal={KSII Transactions on Internet and Information Systems},
year={2016},
volume={10},
number={2},
pages={825-836},
doi={10.3837/tiis.2016.02.021},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959441272&doi=10.3837%2ftiis.2016.02.021&partnerID=40&md5=743e67e85c45fb49b9775dcc65c7f710},
abstract={In this paper, a speed-up technique for the non-local means (NLM) image denoising method based on local binary descriptor (LBD) is proposed. In the NLM, most of the computation time is spent on searching for non-local similar patches in the search window. The local binary descriptor which represents the structure of patch as binary strings is employed to speed up the search process in the NLM. The descriptor allows for a fast and accurate preselection of non-local similar patches by bitwise operations. Using this approach, a tradeoff between time-saving and noise removal can be obtained. Simulations exhibit that despite being principally constructed for speed, the proposed algorithm outperforms in terms of denoising quality as well. Furthermore, a parallel implementation on GPU brings NLM-LBD to real-time image denoising. © 2016 KSII.},
author_keywords={Image denoising;  Local binary descriptor;  Non-local means;  Real time image processing},
keywords={Algorithms;  Bins;  Image processing, Descriptors;  Image denoising algorithm;  Image denoising methods;  Non local means;  Non local means (NLM);  Parallel implementations;  Real-time image processing;  Speed-up techniques, Image denoising},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Shams-Baboli2016142,
author={Shams-Baboli, A. and Shams-Baboli, A.A.},
title={A modified nonlinear filtering technique for removal of high density salt and pepper noise},
journal={Iranian Conference on Machine Vision and Image Processing, MVIP},
year={2016},
volume={2016-February},
pages={142-145},
doi={10.1109/IranianMVIP.2015.7397523},
art_number={7397523},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962812581&doi=10.1109%2fIranianMVIP.2015.7397523&partnerID=40&md5=bc50b95b7db828af031b5a5620b15802},
abstract={In this paper, a very effective nonlinear filtering technique is presented for denoising the image with severe salt & pepper noise. The filter reconstruct a corrupted pixel in three steps: first, it will be replaced by the median of the uncorrupted pixels of its neighbors or average value of them if all of them were noisy. Second, the impulse noises that made in the first step will be found and replaced by salt & pepper noise, third we replace the remaining corrupted pixel by the median or its neighbor's pixel value. The algorithm takes no action on healthy pixels. The proposed algorithm is more effective in removing the salt & pepper noise and also keeps the image features. This algorithm will be test and evaluated by Lena, Boat and Lotus. The results of the simulation show that the proposed method can eliminate salt and pepper noise of densities up to 80% while keeping the edges and fine details sufficiently. Our algorithm has a better performance on all the experiments and shows much more robustness than other algorithms. © 2015 IEEE.},
author_keywords={Median Filtering;  Nonlinear Filter;  Order Statistics Filter;  Salt & Pepper Noise},
keywords={Algorithms;  Computer vision;  Image processing;  Impulse noise;  Median filters;  Nonlinear filtering;  Pixels;  Salt removal, Average values;  Image features;  Median filtering;  Non-linear filtering techniques;  Order statistics filters;  Pepper noise;  Pixel values;  Salt-and-pepper noise, Image denoising},
document_type={Conference Paper},
source={Scopus},
}

@inproceedings{neural-dude,
author={Moon, T. and Min, S. and Lee, B. and Yoon, S.},
title={Neural universal discrete denoiser},
booktitle={Advances in Neural Information Processing Systems},
year={2016},
pages={4779-4787},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85018867712&partnerID=40&md5=f1ebbf03e7430790cd82068980ac4b80},
abstract={We present a new framework of applying deep neural networks (DNN) to devise a universal discrete denoiser. Unlike other approaches that utilize supervised learning for denoising, we do not require any additional training data. In such setting, while the ground-truth label, i.e., the clean data, is not available, we devise "pseudolabels" and a novel objective function such that DNN can be trained in a same way as supervised learning to become a discrete denoiser. We experimentally show that our resulting algorithm, dubbed as Neural DUDE, significantly outperforms the previous state-of-the-art in several applications with a systematic rule of choosing the hyperparameter, which is an attractive feature in practice. © 2016 NIPS Foundation - All Rights Reserved.},
keywords={Deep learning;  Supervised learning, De-noising;  Ground truth;  Hyper-parameter;  Objective functions;  State of the art;  Training data, Deep neural networks},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Neeru2016434,
author={Neeru, N. and Kaur, L.},
title={An experimental analysis on removal of salt and pepper noise from digital images},
journal={Communications in Computer and Information Science},
year={2016},
volume={628 CCIS},
pages={434-441},
doi={10.1007/978-981-10-3433-6_52},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009517266&doi=10.1007%2f978-981-10-3433-6_52&partnerID=40&md5=f7d32205c77e640388f43b3f1e46d31a},
abstract={Images are normally degraded with noise. The main goal of the denoising technique is to eliminate the noise with minimum distortion. In this paper, work has been done to remove the salt & pepper noise from some of the standard images. The image denoising has been performed with median filter (MF), adaptive median filter (AMF), decision based unsymmetrical trimmed median filter (DBUTMF), modified decision based unsymmetric trimmed median filter (MDBUTMF) and decision based unsymmetric trimmed midpoint filter (DBUTMPF). The performance of each technique has been evaluated on the basis of four parameters namely, signal to noise ratio (SNR), Structure similarity index measure (SSIM), edge preservation index (EPI) and multiscale structure similarity index measure (MSSSIM). © Springer Nature Singapore Pte Ltd. 2016.},
author_keywords={Filters;  Image denoising;  Noise detection;  Salt & pepper noise},
keywords={Adaptive filters;  Filters (for fluids);  Median filters;  Salt removal;  Signal to noise ratio, Adaptive Median Filter (AMF);  De-noising techniques;  Experimental analysis;  Multi-scale structures;  Noise detection;  Pepper noise;  Salt-and-pepper noise;  Structure similarity, Image denoising},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Halder2016635,
author={Halder, A. and Halder, S. and Chakraborty, S.},
title={A novel iterative salt-and-pepper noise removal algorithm},
journal={Advances in Intelligent Systems and Computing},
year={2016},
volume={404},
pages={635-643},
doi={10.1007/978-81-322-2695-6_54},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983189674&doi=10.1007%2f978-81-322-2695-6_54&partnerID=40&md5=58e1c3ee0a5fed418a2aa6a00e87715b},
abstract={This paper proposes a novel iterative algorithm for removal of saltand- pepper impulse noises. Even if the noise level is as high as 90%, this proposed methodology ensures elimination of all the impulse noises while restoring the fine details of gray-scale images. Most of the salt-and-pepper noise removal techniques try to search for impulse noise from the images, but this proposed algorithm searches for the non-noisy points and removes the impulse points found in vicinity. The algorithm does the process iteratively but with low time complexity compared to most of the modern powerful algorithms. This simple straight forward algorithm produces the denoising image that gives better peak signal-to-noise ratio (PSNR) than other existing algorithms. © Springer India 2016.},
author_keywords={Median filtering;  PSNR;  Salt-and-pepper noise},
keywords={Algorithms;  Impulse noise;  Intelligent computing;  Iterative methods;  Median filters;  Salt removal;  Signal to noise ratio, Forward algorithms;  Iterative algorithm;  Median filtering;  Peak signal to noise ratio;  PSNR;  Salt-and-pepper impulse noise;  Salt-and-pepper noise;  Salt-and-pepper noise removal, Image denoising},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Dong2015789,
author={Dong, F. and Chen, Y. and Kong, D.-X. and Yang, B.},
title={Salt and pepper noise removal based on an approximation of l0 norm},
journal={Computers and Mathematics with Applications},
year={2015},
volume={70},
number={5},
pages={789-804},
doi={10.1016/j.camwa.2015.05.026},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84945483391&doi=10.1016%2fj.camwa.2015.05.026&partnerID=40&md5=dc8381b259b3e8e98cd6d113ee4cbda3},
abstract={In this paper, we present a novel variational model for salt and pepper noise removal, and an efficient numerical algorithm for solving it. The proposed model features the use of an approximating function of l0 norm to measure the closeness of the reconstructed and observed images at the pixels which are not the candidates of the noisy pixels. In addition, the total variation (TV) of the image on the entire image domain is minimized for edge-preserving smoothing. When solving the proposed minimization problem, to reduce the computational complexity from the expression of the approximating function, we use the dual forms of both TV and data terms, and find the solution of the corresponding primal-dual problem. Numerous experiments on real images, and comparisons with TV-L2, TV-L1, and adaptive median filter (AMF) indicate the effectiveness and robustness of the proposed method in salt and pepper noise removal. © 2015 Elsevier Ltd.},
author_keywords={l0 norm;  First order primal-dual algorithm;  Salt and pepper noise},
keywords={Algorithms;  Electromagnetic wave emission;  Median filters;  Pixels, Adaptive Median Filter (AMF);  Edge-preserving smoothing;  l0 norm;  Minimization problems;  Primal dual algorithms;  Salt-and-pepper noise;  Salt-and-pepper noise removal;  Variational modeling, Salt removal},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Konar20151225,
author={Konar, D. and Bhattacharyya, S. and Das, N. and Panigrahi, B.K.},
title={A Quantum Bi-Directional Self-Organizing Neural Network (QBDSONN) for binary image denoising},
journal={2015 International Conference on Advances in Computing, Communications and Informatics, ICACCI 2015},
year={2015},
pages={1225-1230},
doi={10.1109/ICACCI.2015.7275780},
art_number={7275780},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946234417&doi=10.1109%2fICACCI.2015.7275780&partnerID=40&md5=13dad056dd2a4d6321a4983062a1061f},
abstract={A Quantum Bi-directional Self-Organizing Neural Network (QBDSONN) architecture suitable for binary image denoising in real time is proposed in this article. It is composed of three second order neighborhood topology based interconnected layers of neurons (represented by qubits) known as input, intermediate and output layers. Moreover, it does not use any quantum back-propagation algorithm for the adjustment of its interconnection weights. Instead, it resorts to a counter-propagation of quantum states of the intermediate layer and the output layer. In the proposed architecture, the inter-connection weights and activation values are represented by rotation gates. The quantum neurons of each network layer follow a cellular network pattern and are fully intra-connected to each other. QBDSONN self-organizes the quantized input image information by means of the counter-propagating fashion of the quantum network states of the intermediate and output layers of the architecture. A quantum measurement at the output layer collapses superposition of quantum states of the processed information thereby yielding the desired outputs once the network attains stability. Applications of QBDSONN are demonstrated on the denoising of a synthetic and real life spanner image with different degrees of uniform noise and Gaussian noise. Comparative results indicate that QBDSONN outperforms its classical counterpart in terms of time and also it retains the shapes of the denoised images with great precision. © 2015 IEEE.},
author_keywords={Bi-directional self-organizing neural network;  Binary object extraction;  Quantum bidirectional self-organizing neural network;  Quantum Computing},
keywords={Backpropagation;  Binary images;  Gaussian noise (electronic);  Image denoising;  Network architecture;  Network layers;  Quantum computers;  Quantum optics, Binary objects;  Classical counterpart;  Interconnection weight;  Neighborhood topology;  Processed information;  Proposed architectures;  Quantum Computing;  Self-organizing neural network, Neural networks},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Wang2015,
author={Wang, Y. and Adhami, R. and Fu, J.},
title={A new machine learning algorithm for removal of salt and pepper noise},
journal={Proceedings of SPIE - The International Society for Optical Engineering},
year={2015},
volume={9631},
doi={10.1117/12.2197113},
art_number={96311R},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946100900&doi=10.1117%2f12.2197113&partnerID=40&md5=cdd7965da38c07b99aac9502c59b153d},
abstract={Supervised machine learning algorithm has been extensively studied and applied to different fields of image processing in past decades. This paper proposes a new machine learning algorithm, called margin setting (MS), for restoring images that are corrupted by salt and pepper impulse noise. Margin setting generates decision surface to classify the noise pixels and non-noise pixels. After the noise pixels are detected, a modified ranked order mean (ROM) filter is used to replace the corrupted pixels for images reconstruction. Margin setting algorithm is tested with grayscale and color images for different noise densities. The experimental results are compared with those of the support vector machine (SVM) and standard median filter (SMF). The results show that margin setting outperforms these methods with higher Peak Signal-to-Noise Ratio (PSNR), lower mean square error (MSE), higher image enhancement factor (IEF) and higher Structural Similarity Index (SSIM). © 2015 SPIE.},
author_keywords={Margin setting;  Noise removal;  Salt and pepper noise},
keywords={Algorithms;  Artificial intelligence;  Color image processing;  Image processing;  Impulse noise;  Learning systems;  Mean square error;  Median filters;  Pixels;  Salt removal;  Signal to noise ratio;  Supervised learning;  Support vector machines, Margin setting;  Noise removal;  Peak signal to noise ratio;  Salt-and-pepper impulse noise;  Salt-and-pepper noise;  Standard median filter;  Structural similarity indices (SSIM);  Supervised machine learning, Learning algorithms},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Li2015172,
author={Li, Z. and Cheng, Y. and Tang, K. and Xu, Y. and Zhang, D.},
title={A salt & pepper noise filter based on local and global image information},
journal={Neurocomputing},
year={2015},
volume={159},
number={1},
pages={172-185},
doi={10.1016/j.neucom.2014.12.087},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84933279167&doi=10.1016%2fj.neucom.2014.12.087&partnerID=40&md5=84e1ae20eeee70f6b989b376c6e15d9b},
abstract={Existing salt & pepper noise filters only use local image information to detect noise pixels, and neglect global image information. This makes them inapplicable to images with noise-free pixel blocks composed of uncorrupted pixels of gray level extremes, either 0 or 255. In addition, existing filters are hard to simultaneously obtain low miss detection (MD) and low false alarm (FA) in noise detection. To alleviate these issues, we proposed an innovative noise filter based on local and global image information. The proposed filter developed an image block-based method to more accurately estimate noise density of an image, and presented a global image information-based noise detection rectification method. The noise density estimation result was used in subsequent noise detection and rectification stages. Furthermore, the proposed filter combined and slightly revised noise detection schemes of two existing switching filters to improve the accuracy of noise detection. Experimental results on a series of images showed that the proposed filter achieved significant improvement, especially on images with noise-free pixel blocks of gray level extremes. © 2015 Elsevier B.V.},
author_keywords={Global information;  Image denoising;  Image thresholding;  Local information;  Salt & pepper noise},
keywords={Pixels, Global image information;  Global informations;  Image information;  Image thresholding;  Local information;  Noise detection;  Pepper noise;  Switching filter, Image denoising, Article;  controlled study;  filter;  image processing;  information processing;  MDWF filter;  noise;  noise density estimation;  noise detection reactification;  noise restoration;  priority journal;  salt and pepper noise;  sound detection;  switching based adaptive weighted mean filter},
document_type={Article},
source={Scopus},
}

@ARTICLE{SyamalaJayaSree2015521,
author={Syamala Jaya Sree, P. and Pattnaik, P.K. and Ghrera, S.P.},
title={A novel algorithm for suppression of salt and pepper impulse noise in fingerprint images using B-spline interpolation},
journal={Advances in Intelligent Systems and Computing},
year={2015},
volume={328},
pages={521-528},
doi={10.1007/978-3-319-12012-6_57},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84919359998&doi=10.1007%2f978-3-319-12012-6_57&partnerID=40&md5=ed272a483e0f6b7c41de772ac1ed91c5},
abstract={The quality of Finger Print Images in image forensics plays a vital role in the the accuracy of biometric based identification and authentication system. To suppress the salt and pepper noise in fingerprint images, B-Splines have been used for interpolation. In this paper, a two stage novel and efficient algorithm for suppression of salt and pepper impulse noise for noise levels ranging from 15% to 95% using B-splines interpolation is being proposed. The algorithm removes salt and pepper impulse noise from the image in the first stage and in second stage, an edge preserving algorithm has been proposed which regularizes the edges that have been deformed during noise removal process. © Springer International Publishing Switzerland 2015.},
author_keywords={B-Spline interpolation;  Fingerprint images;  Image forensics},
keywords={Algorithms;  Biometrics;  Computation theory;  Edge detection;  Impulse noise;  Intelligent computing;  Salt removal;  Ship propellers, Authentication systems;  B-spline interpolations;  Edge preserving algorithm;  Fingerprint images;  Image forensics;  Novel algorithm;  Salt-and-pepper impulse noise;  Salt-and-pepper noise, Interpolation},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Vijaykumar20141145,
author={Vijaykumar, V.R. and Santhana Mari, G. and Ebenezer, D.},
title={Fast switching based median-mean filter for high density salt and pepper noise removal},
journal={AEU - International Journal of Electronics and Communications},
year={2014},
volume={68},
number={12},
pages={1145-1155},
doi={10.1016/j.aeue.2014.06.002},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922745796&doi=10.1016%2fj.aeue.2014.06.002&partnerID=40&md5=4485812bee43d75960c09028c5157716},
abstract={This paper proposes a fast switching based median-mean filter for high density salt and pepper noise in images. The extreme minimum value and extreme maximum value of the noisy image are used to identify the noise pixels. In the filtering stage, the corrupted pixel is replaced either by median value or mean value based on the number of noise free pixels in the filtering window. The qualitative and quantitative results show that the proposed filter outperforms the other switching based filters namely ACWMF, PSMF, AMF, DBA and MDBUTMF in terms of noise removal and edge preservation for noise densities varying from 10% to 90%. © 2014 Elsevier GmbH. All rights reserved.},
author_keywords={Image restoration;  Impulse detection;  Mean filter;  Median filter;  Salt and pepper noise},
keywords={Image reconstruction;  Pixels;  Salt removal, Edge preservations;  Fast switching;  Impulse detection;  Mean filter;  Minimum value;  Quantitative result;  Salt-and-pepper noise;  Salt-and-pepper noise removal, Median filters},
document_type={Article},
source={Scopus},
}

@ARTICLE{Pyatykh2014748,
author={Pyatykh, S. and Hesser, J.},
title={Salt and pepper noise removal in binary images using image block prior probabilities},
journal={Journal of Visual Communication and Image Representation},
year={2014},
volume={25},
number={5},
pages={748-754},
doi={10.1016/j.jvcir.2014.02.001},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897749050&doi=10.1016%2fj.jvcir.2014.02.001&partnerID=40&md5=698f161f598e5fbe0ee4e38b32c8c101},
abstract={During scanning and transmission, images can be corrupted by salt and pepper noise, which negatively affects the quality of subsequent graphic vectorization or text recognition. In this paper, we present a new algorithm for salt and pepper noise suppression in binary images. The algorithm consists of the computation of block prior probabilities from training noise-free images; noise level estimation; and the maximum a posteriori probability estimation of each image block. Our experiments show that the proposed method performs significantly better than the state of the art techniques. © 2014 Elsevier Inc. All rights reserved.},
author_keywords={Bayesian inference;  Binary images;  Image denoising;  Image filtering;  Image restoration;  Impulse noise;  Salt and pepper noise;  Training methods},
keywords={Bayesian inference;  Image filtering;  Maximum a posteriori probability estimations (MAP);  Noise level estimation;  Salt-and-pepper noise;  Salt-and-pepper noise removal;  State-of-the-art techniques;  Training methods, Algorithms;  Bayesian networks;  Binary images;  Character recognition;  Image reconstruction;  Impulse noise;  Inference engines;  Probability distributions;  Salt removal, Image denoising},
document_type={Article},
source={Scopus},
}

@ARTICLE{Li2014113,
author={Li, Z. and Liu, G. and Xu, Y. and Cheng, Y.},
title={Modified directional weighted filter for removal of salt & pepper noise},
journal={Pattern Recognition Letters},
year={2014},
volume={40},
number={1},
pages={113-120},
doi={10.1016/j.patrec.2013.12.022},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893496694&doi=10.1016%2fj.patrec.2013.12.022&partnerID=40&md5=c59ee677cc2a52d5e3b81bfd414632af},
abstract={Switching median filter is a popular type of salt & pepper noise removal technique in recent years. It first detects noise pixels in an image, and then only restores the noise pixels by using the median or its variant of filtering window. Existing directional weighted median filters suffer their own deficiencies when detecting and restoring noise pixels. In this paper, after deeply analyzing the reasons that cause the deficiencies, we propose a modified directional weighted filter to alleviate the issues. The new filter first detects salt & pepper noise by combining existing directional gray level differences with additional judgment of gray level extremes. Then the noise density of each noise pixel's non-recursive local window is estimated, and an innovative weighted gray level mean of a recursive or non-recursive filtering window is taken as the restored gray level according to noise density. Experimental results on a series of images show that the proposed algorithm achieves significant improvements in terms of noise suppression and detail preservation, especially when the noise density is high. © 2014 Elsevier Inc. All rights reserved.},
author_keywords={Edge direction;  Image denoising;  Iterative filtering;  Median filter;  Salt & pepper noise},
keywords={Detail preservation;  Edge direction;  Gray level differences;  Iterative filtering;  Noise suppression;  Pepper noise;  Switching median filters;  Weighted median filter, Image denoising;  Pixels;  Restoration;  Salt removal, Median filters},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Chaitanya2014,
author={Chaitanya, N.K. and Sreenivasulu, P.},
title={Removal of salt and pepper noise using Advanced Modified Decision based Unsymmetric Trimmed Median Filter},
journal={2014 International Conference on Electronics and Communication Systems, ICECS 2014},
year={2014},
doi={10.1109/ECS.2014.6892524},
art_number={6892524},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908627685&doi=10.1109%2fECS.2014.6892524&partnerID=40&md5=0aa30ecf9ff1249a14ae7063ce3cd76f},
abstract={In this paper we are presenting a novel approach for removal of salt and pepper noise from the high density salt & pepper noisy images, using Iterative Modified Decision based Unsymmetric Trimmed Median Filter. The existing MDBUTMF is unable to restore the original image from the noisy one if noise density is more than 70%. The performance of the proposed method is analyzed by using various qualities of metrics, such as Mean Square Error (MSE) and Peak Signal to Noise ratio (PSNR). Simulation results clearly show that the proposed method is out performs both in qualitative as well quantitative fidelity criteria, when it is compared with MDBUTMF. © 2014 IEEE.},
author_keywords={Image;  Impulse noise;  Median filter;  Noise density},
keywords={Impulse noise;  Iterative methods;  Mean square error;  Salt removal;  Signal to noise ratio, Decision-based;  Image;  Noise density;  Noisy image;  Original images;  Peak signal to noise ratio;  Salt-and-pepper noise, Median filters},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Bhattacharyya2014717,
author={Bhattacharyya, S. and Pal, P. and Bhowmick, S.},
title={Binary image denoising using a quantum multilayer self organizing neural network},
journal={Applied Soft Computing},
year={2014},
volume={24},
pages={717-729},
doi={10.1016/j.asoc.2014.08.027},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908394698&doi=10.1016%2fj.asoc.2014.08.027&partnerID=40&md5=0dead5cd2150e07a71227e2eb51c6db8},
abstract={Several classical techniques have evolved over the years for the purpose of denoising binary images. But the main disadvantages of these classical techniques lie in that an a priori information regarding the noise characteristics is required during the extraction process. Among the intelligent techniques in vogue, the multilayer self organizing neural network (MLSONN) architecture is suitable for binary image preprocessing tasks. In this article, we propose a quantum version of the MLSONN architecture. Similar to the MLSONN architecture, the proposed quantum multilayer self organizing neural network (QMLSONN) architecture comprises three processing layers viz., input, hidden and output layers. The different layers contains qubit based neurons. Single qubit rotation gates are designated as the network layer interconnection weights. A quantum measurement at the output layer destroys the quantum states of the processed information thereby inducing incorporation of linear indices of fuzziness as the network system errors used to adjust network interconnection weights through a quantum backpropagation algorithm. Results of application of the proposed QMLSONN are demonstrated on a synthetic and a real life binary image with varying degrees of Gaussian and uniform noise. A comparative study with the results obtained with the MLSONN architecture and the supervised Hopfield network reveals that the QMLSONN outperforms the MLSONN and the Hopfield network in terms of the computation time. © 2014 Elsevier B.V. All rights reserved.},
author_keywords={Fuzzy set theory;  Hopfield network;  Image denoising;  MLSONN;  Quantum computing-;  Quantum multilayer self organizing neural network},
keywords={Backpropagation;  Binary images;  Computation theory;  Fuzzy set theory;  Hopfield neural networks;  Image denoising;  Interconnection networks (circuit switching);  Multilayers;  Network architecture;  Network layers;  Quantum optics;  Qubits, Hopfield Networks;  Intelligent techniques;  Interconnection weight;  MLSONN;  Network interconnections;  Quantum Computing;  Self-organizing neural network;  Single-qubit rotations, Multilayer neural networks},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Verma2014233,
author={Verma, O.P. and Arora, S. and Singh, I.},
title={A novel approach for salt and pepper noise removal based on heuristic analysis of neighboring pixels},
journal={2014 International Conference on Computing for Sustainable Global Development, INDIACom 2014},
year={2014},
pages={233-238},
doi={10.1109/IndiaCom.2014.6828134},
art_number={6828134},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903827286&doi=10.1109%2fIndiaCom.2014.6828134&partnerID=40&md5=3d37ef914e7c54e09dd076ee9b12e0ff},
abstract={This paper presents a novel approach designed for removal of salt and pepper noise based on heuristic analysis of the neighboring pixels (SPHN). It is a two stage filter; in the first stage the noisy pixels are detected. Only the pixels classified as noisy are subjected to the filtering stage. In the detector stage the proposed algorithm analyses the neighborhood of the pixel under consideration, based on this analysis it classifies the pixel as noisy or noise-free. The noisy pixels are then subjected to filtering. © 2014 IEEE.},
author_keywords={median filter;  noise detector;  salt and pepper noise;  two stage filter},
keywords={Median filters;  Salt removal, Algorithm analysis;  Heuristic analysis;  Noise detectors;  Noisy pixels;  Salt-and-pepper noise;  Salt-and-pepper noise removal;  two stage filter, Pixels},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Ramakrishnan2013365,
author={Ramakrishnan, N.K. and Thulasidharan, P.P. and Panicker, A.D. and Nair, M.S.},
title={Multi-pass unsymmetric trimmed median filter for salt-and-pepper noise removal},
journal={Lecture Notes in Electrical Engineering},
year={2013},
volume={221 LNEE},
number={VOL. 1},
pages={365-374},
doi={10.1007/978-81-322-0997-3_33},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885221787&doi=10.1007%2f978-81-322-0997-3_33&partnerID=40&md5=db1e9c7a8f32d2a1b42a90b13671ea6f},
abstract={Restoration of original image corrupted with high density salt-and-pepper noise is still a challenging task. In this letter, we propose here a new method; Multi-Pass Unsymmetric Trimmed Median Filter (MPUTMF) [versions 'a' and 'b'], to restore an image affected with high density salt-and-pepper noise, with better edge preservation. The MPUTMFa can do the restoration within two passes over the noisy image using the preprocessed pixels obtained in the same pass, where as MPUTMFb can take up to six passes over the noisy image for restoration without using the preprocessed pixels. MPUTMFb is computationally efficient on single core processor systems where as MPUTMFb is well suited to be implemented on parallel processing systems or GPUs to achieve higher computational efficiency. The proposed methods are compared with conventional as well as advanced algorithms like Median Filter (MF), Adaptive Median Filter (AMF), Efficient Decision Based Algorithm (EDBA), Improved Decision Based Algorithm (IDBA) and Modified Decision Based Unsymmetric Trimmed Median Filter (MDBUTMF). The experimental analysis (visual and quantitative) shows that our method gives better results on images affected with high density salt-and-pepper noise. Peak Signal-to-Noise Ratio (PSNR) and Image Enhancement Factor (IEF) are used for quantitatively evaluating the results of proposed algorithm(s). © 2013 Springer.},
author_keywords={Image restoration;  Impulse noise;  Median filter;  Parallel processing;  Salt-and-pepper noise;  Trimmed median filter},
keywords={Adaptive Median Filter (AMF);  Computationally efficient;  Decision-based algorithms;  Parallel processing;  Peak signal-to-noise ratio;  Salt-and-pepper noise;  Salt-and-pepper noise removal;  Single-core processors, Algorithms;  Computational efficiency;  Image reconstruction;  Impulse noise;  Median filters;  Parallel processing systems;  Pixels;  Program processors;  Restoration, Salt removal},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Sree2013111,
author={Sree, P.S.J. and Kumar, P. and Siddavatam, R. and Verma, R.},
title={Salt-and-pepper noise removal by adaptive median-based lifting filter using second-generation wavelets},
journal={Signal, Image and Video Processing},
year={2013},
volume={7},
number={1},
pages={111-118},
doi={10.1007/s11760-011-0210-3},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871922835&doi=10.1007%2fs11760-011-0210-3&partnerID=40&md5=058003cd5f7041b6d3650d3d2ddc4447},
abstract={In this paper, we propose a novel adaptive median-based lifting filter for image de-noising which has been corrupted by homogeneous salt and pepper noise. The median-based lifting filter removes the noise of the input image by calculating the median of the neighboring significant pixels. The algorithm for image noise removal uses the lifting scheme of the second-generation wavelets in conjunction with the proposed adaptive median-based lifting filter. The experimental results demonstrate the efficiency of the proposed method. The proposed algorithm is compared with all the basic filters, and it is found that our method outperforms many other algorithms and it can remove salt and pepper noise with a noise level as high as 90%. The algorithm works exceedingly well for all levels of noise, as illustrated in terms of peak signal-to-noise ratio (PSNR) and structural similarity index (SSIM) measures. © 2011 Springer-Verlag London Limited.},
author_keywords={Adaptive median filter;  Lifting filter;  Salt and pepper noise;  Second-generation wavelets},
keywords={Adaptive median filter;  Image noise;  Input image;  Lifting filter;  Lifting schemes;  Noise levels;  Peak signal-to-noise ratio;  Salt-and-pepper noise;  Salt-and-pepper noise removal;  Second generation wavelet;  Structural similarity, Algorithms;  Image denoising;  Image segmentation;  Salt removal, Median filters},
document_type={Article},
source={Scopus},
}

@ARTICLE{Zhao20122273,
author={Zhao, F. and Ma, R.-C. and Ma, J.-Q.},
title={An algorithm for salt and pepper noise removal based on information entropy},
journal={Applied Mechanics and Materials},
year={2012},
volume={220-223},
pages={2273-2279},
doi={10.4028/www.scientific.net/AMM.220-223.2273},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870619271&doi=10.4028%2fwww.scientific.net%2fAMM.220-223.2273&partnerID=40&md5=1e5ef6a009353302b476b264e714c3c0},
abstract={By using information entropy to estimate the distribution uniformity of the pixels with a same gray level, an accurate salt and pepper noise detection method is presented based on the statistical property of salt and pepper noise. And then, a new modified mean filter is designed, which sets up noise-centre filtering windows, Moreover, the weighted means are calculated by merely using the non-noise points in each filtering window. The presented filter can efficiently preserve the details of images, avoid the affection of noise points on the restore points, and reduce the dimness of the noise points. Experimental results show that this algorithm has the better performance on noise detection, noise filtering, and the protection of detail. © (2012) Trans Tech Publications, Switzerland.},
author_keywords={Image denoising;  Information entropy;  Median filtering;  Salt and pepper noise},
keywords={Distribution uniformity;  Gray levels;  Information entropy;  Mean filter;  Median filtering;  Noise detection;  Noise filtering;  Salt-and-pepper noise;  Salt-and-pepper noise removal;  Statistical properties;  Weighted mean, Algorithms;  Design;  Image denoising;  Salt removal, Median filters},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Daiyan2012107,
author={Daiyan, G.M. and Mottalib, M.A. and Rahman, M.M.},
title={High performance decision based median filter for salt and pepper noise removal in images},
journal={Proceeding of the 15th International Conference on Computer and Information Technology, ICCIT 2012},
year={2012},
pages={107-112},
doi={10.1109/ICCITechn.2012.6509707},
art_number={6509707},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84878105208&doi=10.1109%2fICCITechn.2012.6509707&partnerID=40&md5=971141ece04af3ceeaaf9264d4a4250a},
abstract={A high performance decision based median filter is proposed for removal of salt and pepper in images. It is an enhanced Adaptive Switching Median filter which initially detects noise pixels iteratively through several phases and replaces the noisy pixels with median value. It calculates median value without considering noisy pixels to improve the performance of median filter for high density noise. Detection of noise is done by expanding the mask until 7×7 to maintain local information extraction. Moreover, the processing pixel is replaced by last processed pixel if the algorithm fails to detect noise free pixel at 7×7. If the noise free median value is not available at 7×7 processing window, the last processed pixel take into consideration if it is noise free. If the last processed pixel is noisy, the algorithm select a window size with 15×15 dimension and calculate the number of 0's and 255's in the processing window. Then replace the processing pixel with 0 or 255 which is more in number in the selected window. Experiment result shows that it can provide very high quality restored images for images that are contaminated by 'salt & pepper' noise, especially when the noise density is large. © 2012 IEEE.},
author_keywords={Adaptive Switching Median filter;  Salt and Pepper Noise},
keywords={Adaptive switching;  Decision-based;  Local information;  Noise density;  Processing windows;  Salt and peppers;  Salt-and-pepper noise;  Salt-and-pepper noise removal, Algorithms;  Information technology;  Iterative methods;  Median filters;  Salt removal, Pixels},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Raza2012,
author={Raza, M.T. and Sawant, S.},
title={High density salt and pepper noise removal through decision based partial trimmed global mean filter},
journal={3rd Nirma University International Conference on Engineering, NUiCONE 2012},
year={2012},
doi={10.1109/NUICONE.2012.6493236},
art_number={6493236},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876489994&doi=10.1109%2fNUICONE.2012.6493236&partnerID=40&md5=1e33c42d311f1b107a427d1ac95b3290},
abstract={Denoising is an important problem in signal and image processing. In this paper a denoising algorithm is proposed which eliminates salt and pepper noise from digital images that are highly corrupted by salt and pepper noise. Several methods have been introduced to remove fixed value impulse noise (salt and pepper noise) from digital images such as median filter (MF), adaptive median filter (AMF), Decision based algorithms (DBA) etc. Many of these algorithms fail while removing the noise at high density and do not preserve fine details of the image. The proposed algorithm (PA) shows better results than existing filtering methods. The algorithm tested and compared for Peak Signal-to-Noise Ratio (PSNR) and Image Enhancement Factor (IEF) with different existing methods. © 2012 IEEE.},
author_keywords={Image denoising;  Median filter;  nonlinear filter;  salt and pepper noise},
keywords={Adaptive Median Filter (AMF);  Decision-based algorithms;  Fixed-value impulse noise;  Nonlinear filter;  Peak signal-to-noise ratio;  Salt-and-pepper noise;  Salt-and-pepper noise removal;  Signal and image processing, Algorithms;  Engineering education;  Image processing;  Impulse noise;  Median filters;  Salt removal, Image denoising},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Jalali20123092,
author={Jalali, S. and Weissman, T.},
title={Denoising via MCMC-based lossy compression},
journal={IEEE Transactions on Signal Processing},
year={2012},
volume={60},
number={6},
pages={3092-3100},
doi={10.1109/TSP.2012.2190597},
art_number={6168286},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861133802&doi=10.1109%2fTSP.2012.2190597&partnerID=40&md5=329d05dd989140f45fb294f3b2142f6b},
abstract={It has been established in the literature, in various theoretical and asymptotic senses, that universal lossy compression followed by some simple postprocessing results in universal denoising, for the setting of a stationary ergodic source corrupted by additive white noise. However, this interesting theoretical result has not yet been tested in practice in denoising simulated or real data. In this paper, we employ a recently developed MCMC-based universal lossy compressor to build a universal compression-based denoising algorithm. We show that applying this iterative lossy compression algorithm with appropriately chosen distortion measure and distortion level, followed by a simple derandomization operation, results in a family of denoisers that compares favorably (both theoretically and in practice) with other MCMC-based schemes, and with the discrete universal denoiser DUDE. © 2012 IEEE.},
author_keywords={Compression-based denoising;  Denoising;  Markov chain Monte Carlo;  Simulated annealing;  Universal lossy compression},
keywords={Additive white noise;  Compression-based denoising;  De-noising;  Derandomization;  Distortion measures;  Lossy compressions;  Markov chain Monte Carlo;  Stationary ergodic sources;  Theoretical result, Algorithms;  Data compression;  Simulated annealing, White noise},
document_type={Review},
source={Scopus},
}

@ARTICLE{He2011,
author={He, Y.-M. and Zhang, G.-B. and Qian, X.-Y.},
title={Salt and pepper noise removal algorithm based on neighbourhood mean},
journal={Nanjing Li Gong Daxue Xuebao/Journal of Nanjing University of Science and Technology},
year={2011},
volume={35},
number={6},
pages={764-767+785},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863045895&partnerID=40&md5=36ca2b19b0bc51cf108cf21f58fa9668},
abstract={To improve the image effect, a filter algorithm for image noise removal suitable for salt and pepper noise is proposed based on the correlation of the neighbourhood. The pixels contaminated by salt and pepper noise are detected by using the maximum-minimum principle. Eight pixels near the contaminated one are divided into two classes according to their distances. The gray value of contaminated pixel is reconstructed by the mean of those uncontaminated pixels with near distance. The gray value of contaminated pixel is reconstructed by the mean of those uncontaminated pixels with far distance if all the pixels with near distance are contaminated. Computer simulation results show that the proposed algorithm with superior peak signal-to-noise ratio can restrain the noise and preserve the detailed information of images.},
author_keywords={Filter;  Image noise removal;  Maximum-minimum principle;  Neighbourhood mean;  Peak signal-to-noise ratio;  Salt and pepper noise},
keywords={Filter;  Image noise;  Maximum-minimum principle;  Neighbourhood;  Peak signal-to-noise ratio;  Salt and pepper noise, Algorithms;  Computer simulation;  Contamination;  Salt removal;  Signal to noise ratio, Pixels},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Kosgiker2011,
author={Kosgiker, G.M.},
title={Efficient algorithm for salt and pepper noise removal},
journal={Proceedings of SPIE - The International Society for Optical Engineering},
year={2011},
volume={8009},
doi={10.1117/12.896169},
art_number={800903},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960856167&doi=10.1117%2f12.896169&partnerID=40&md5=88eb38a3d4a121039c59ced4abacbe27},
abstract={In this paper an efficient nonlinear decision based filter is proposed to remove salt and pepper impulse noise. Propose filter is a two stage filter that incorporates a powerful impulse noise detection method, called the modified boundary discriminative noise detection (MBDND) [1] to determine whether the current pixel is corrupted or not. In the second stage a Euclidean distance algorithm [2] is used to restore the corrupted pixels. Extensive experimental results demonstrate that proposed filters performs significantly better than many existing, well accepted and recently proposed median and decision based filters for both gray scale and color images corrupted up to 70% of salt and pepper noise. © 2011 Copyright Society of Photo-Optical Instrumentation Engineers (SPIE).},
author_keywords={decision based filters;  discriminative noise detection;  Euclidean distance;  image restoration;  impulse noise},
keywords={Color images;  Decision based filter;  Efficient algorithm;  Euclidean distance;  Euclidean distance algorithm;  Gray scale;  Impulse noise detection;  Noise detection;  Salt-and-pepper impulse noise;  Salt-and-pepper noise;  Salt-and-pepper noise removal;  Two stage, Algorithms;  Image reconstruction;  Imaging systems;  Impulse noise;  Pixels;  Restoration, Salt removal},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{dude-i,
author={Motta, G. and Ordentlich, E. and Ramírez, I. and Seroussi, G. and Weinberger, M.J.},
title={The {iDUDE} framework for grayscale image denoising},
journal={IEEE Transactions on Image Processing},
year={2011},
volume={20},
number={1},
pages={1-21},
doi={10.1109/TIP.2010.2053939},
art_number={5497153},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-79551515178&doi=10.1109%2fTIP.2010.2053939&partnerID=40&md5=f1972826e0844865066382978b2e5dc5},
abstract={We present an extension of the discrete universal denoiser DUDE, specialized for the denoising of grayscale images. The original DUDE is a low-complexity algorithm aimed at recovering discrete sequences corrupted by discrete memoryless noise of known statistical characteristics. It is universal, in the sense of asymptotically achieving, without access to any information on the statistics of the clean sequence, the same performance as the best denoiser that does have access to such information. The DUDE, however, is not effective on grayscale images of practical size. The difficulty lies in the fact that one of the DUDE's key components is the determination of conditional empirical probability distributions of image samples, given the sample values in their neighborhood. When the alphabet is relatively large (as is the case with grayscale images), even for a small-sized neighborhood, the required distributions would be estimated from a large collection of sparse statistics, resulting in poor estimates that would not enable effective denoising. The present work enhances the basic DUDE scheme by incorporating statistical modeling tools that have proven successful in addressing similar issues in lossless image compression. Instantiations of the enhanced framework, which is referred to as iDUDE, are described for examples of additive and nonadditive noise. The resulting denoisers significantly surpass the state of the art in the case of salt and pepper (S&P) and -ary symmetric noise, and perform well for Gaussian noise. © 2010 IEEE.},
author_keywords={Context-based denoising;  discrete universal denoiser (DUDE) algorithm;  discrete universal denoising;  Gaussian noise;  image denoising;  impulse noise},
keywords={De-noising;  discrete universal denoiser (DUDE) algorithm;  Discrete universal denoising;  Gaussian noise;  image denoising, Algorithms;  Gaussian distribution;  Gaussian noise (electronic);  Image compression;  Impulse noise, Noise pollution control},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Wan20101055,
author={Wan, Y. and Chen, Q.},
title={A novel quadratic type variational method for efficient salt-and-pepper noise removal},
journal={2010 IEEE International Conference on Multimedia and Expo, ICME 2010},
year={2010},
pages={1055-1060},
doi={10.1109/ICME.2010.5583306},
art_number={5583306},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-78349260424&doi=10.1109%2fICME.2010.5583306&partnerID=40&md5=eed7811ceec0276611a87d2ec4843fe4},
abstract={Salt-and-pepper impulse noise is one commonly encountered noise type during image and video communication. So far the state of the art methods can reasonably restore images corrupted by salt-and-pepper noise whose level is up to 90%[1]. We propose a novel quadratic type variational formulation of this noise removal problem. This approach first uses a simple yet fast method to eliminate all salt-and-pepper noise pixels as well as possibly some clean pixels, then the clean image is efficiently reconstructed from the remaining clean pixels by minimizing a carefully designed functional. Because the functional is quadratic type, fast unconditional convergence is guaranteed. Simulation results show that the proposed method outperforms previously published results and can tolerate noise level of as much as 95%. © 2010 IEEE.},
author_keywords={Image denoising;  Impulse noise;  Salt-andpepper noise;  Variational method},
keywords={Fast methods;  Image and video communication;  Image de-noising;  Noise levels;  Noise removal;  Noise types;  Restore image;  Salt-and-pepper impulse noise;  Salt-and-pepper noise;  Salt-and-pepper noise removal;  Simulation result;  State-of-the-art methods;  Unconditional convergence;  Variational formulation;  Variational methods, Image processing;  Impulse noise;  Noise pollution control;  Ordinary differential equations;  Pixels, Salt removal},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Su20101648,
author={Su, H.-I. and Weissman, T.},
title={Universal lossless compression-based denoising},
journal={IEEE International Symposium on Information Theory - Proceedings},
year={2010},
pages={1648-1652},
doi={10.1109/ISIT.2010.5513338},
art_number={5513338},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955683564&doi=10.1109%2fISIT.2010.5513338&partnerID=40&md5=9a1dcafdb03bc7a72e11967248d5fe8c},
abstract={In a discrete denoising problem, if the denoiser knows the clean source distribution, the Bayes optimal denoiser is the Bayes response of the posterior distribution of the source given the noisy observations. However, in many applications the source distribution is unknown. We consider the Bayes response based on the approximate posterior distribution induced by a universal lossless compression code. Motivated by this approach, we present the empirical conditional entropy-based denoiser. Simulations show that when the source alphabet is small, the proposed denoiser achieves the performance of the Universal Discrete DEnoiser (DUDE). Furthermore, if the alphabet size increases, the proposed denoiser degrades more gracefully than the DUDE. © 2010 IEEE.},
keywords={Alphabet size;  Conditional entropy;  Denoising problems;  Lossless compression;  Noisy observations;  Posterior distributions;  Source alphabet;  Source distribution, Information theory;  Noise pollution control, Image compression},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Fu201093,
author={Fu, B. and Yang, K. and Li, W. and Fan, F.},
title={A salt & pepper noise fast filtering algorithm for grayscale images based on neighborhood correlation detection},
journal={IASP 10 - 2010 International Conference on Image Analysis and Signal Processing},
year={2010},
pages={93-96},
doi={10.1109/IASP.2010.5476154},
art_number={5476154},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954320145&doi=10.1109%2fIASP.2010.5476154&partnerID=40&md5=052c9c934fac118e7559fdce511ffc50},
abstract={A salt & pepper noise fast filtering algorithm for grayscale images based on neighborhood correlation detection is presented. By utilizing a 4×4 pixel template, the algorithm can discriminate and filter various patterns of salt & pepper noise spots or blocks within 2×2 pixel size range. In contrast with many kinds of median filtering algorithm, which may cause image blurring, it has much higher edge-preserving ability. Furthermore, this algorithm is able to synchronously reflect image quality via amount, location and density statistics of salt & pepper noise spots and make good sense to guide parameter selection for imaging systems. © 2010 IEEE.},
author_keywords={Edge-preserving;  Neighborhood correlation;  Pepper noise;  Salt &},
keywords={Correlation detection;  Density statistics;  Edge preserving;  Fast filtering algorithm;  Gray-scale images;  Guide parameters;  Image blurring;  Median filtering algorithm;  Neighborhood correlation;  Pepper noise;  Pixel size, Algorithms;  Image analysis;  Image quality;  Kalman filters;  Pixels;  Regression analysis;  Signal detection;  Signal processing, Edge detection},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Ma2010,
author={Ma, P. and Meng, L. and Zhang, Y.},
title={Improved DUDE model for image denoising},
journal={Bandaoti Guangdian/Semiconductor Optoelectronics},
year={2010},
volume={31},
number={2},
pages={296-299+311},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953268819&partnerID=40&md5=8601b0a8a2dbca9cea69a4a9fa41c356},
abstract={Considering that there is no universal demising standard, in order to remove the image noise, under the premise of analysis and research on difficulties in image demising, it is briefly explained the basic principles of Discrete Universal Denoiser (DUDE) model recently appeared in this field. Meanwhile, some improvements are made for this new algorithm, in which the pixel neighborhoods are redefined to set up a more accurate method to correct pixel intensities. Then the contaminated images will be demised. Comparisons with the performance of other filtering methods are made. Experimental results show that the method not only reduces the mean square error (MSE), the requirement of memory and prior knowledge or implicit assumption, but also significantly improves the subjective and objective effects of image demising, and its performance is very close to that of HMM(Hidden Markov Model).},
author_keywords={Discrete memory less channel;  Hidden Markov model;  Image demising;  Median filter},
document_type={Article},
source={Scopus},
}

@ARTICLE{Premchaiswadi2010351,
author={Premchaiswadi, N. and Yimgnagm, S. and Premchaiswadi, W.},
title={A scheme for salt and pepper noise reduction and its application for OCR systems},
journal={WSEAS Transactions on Computers},
year={2010},
volume={9},
number={4},
pages={351-360},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-77950127873&partnerID=40&md5=3fd9a3f909443db1aa766ae74c84d1c6},
abstract={This paper presents an algorithm for Salt and Pepper noise reduction which can be applied to binary, gray scale, and color formatted documents. The scheme combines the characteristics of the Applied kFill Algorithm and Median Filter Algorithm by using window sizes of 3×3 and 5×5, depending on the size of the Salt and Pepper noise. The goal of this technique is to increase the PSNR of picture images and improve the quality for scanning documents when using an optical character recognition (OCR) system. The experimental results show that the proposed scheme can remove Salt and Pepper noise better than the Applied kFill Algorithm and Median Filter Algorithm and can significantly improve the recognition accuracy of an optical character recognition (OCR) system.},
author_keywords={Applied kFill;  Image processing;  KFill Algorithm;  Median Filter;  Noise reduction;  OCR systems;  Salt and Pepper noise},
keywords={Applied kFill;  Gray scale;  Median filter;  Median filter algorithms;  Recognition accuracy;  Salt-and-pepper noise;  Window Size, Acoustic noise measurement;  Image processing;  Imaging systems;  Optical character recognition;  Optical data processing, Algorithms},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Hanji2010,
author={Hanji, G. and Latte, M.V.},
title={A new threshold-based median filtering technique for salt and pepper noise removal},
journal={Proceedings of SPIE - The International Society for Optical Engineering},
year={2010},
volume={7546},
doi={10.1117/12.856333},
art_number={754639},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-77949484467&doi=10.1117%2f12.856333&partnerID=40&md5=cd46aa91d62c797794fa38694f893c7b},
abstract={Removing Noise from the image is a challenging problem for the researchers. This paper proposes a two phase threshold based median filtering technique for salt and pepper impulse noise removal. It is implemented as a two pass algorithm: In the first pass corrupted pixels are perfectly detected using min-max strategy and an adaptive working window based on estimated noise density. Second phase is a threshold based filtering technique to correct the corrupted pixels by a valid median. Experimental results have shown that the proposed technique performs far more superior than many of the efficient median based filtering techniques reported in the literature in terms of Peak Signal (PSNR) and visual perception of the images corrupted by impulse noise even to the tune of seventy percent. © 2010 Copyright SPIE - The International Society for Optical Engineering.},
author_keywords={Mean Absolute Error (MAE);  Mean Square Error (MSE);  Peak Signal to Noise Ratio (PSNR);  Salt & Pepper noise;  Threshold value},
keywords={Filtering technique;  Mean absolute error;  Median filtering;  Min-max strategy;  Noise density;  Peak signal to noise ratio;  Peak Signal to Noise Ratio (PSNR);  Pepper noise;  Salt-and-pepper impulse noise;  Salt-and-pepper noise removal;  Second phase;  Two phase;  Visual perception;  Window-based, Block codes;  Digital image storage;  Image processing;  Imaging systems;  Impulse noise;  Mean square error;  Pixels;  Signal to noise ratio;  Strain energy, Salt removal},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Junez-Ferreira2010209,
author={Junez-Ferreira, C.A. and Velasco-Avalos, F.A. and Pastor-Gomez, N.},
title={A salt and pepper noise removal and restoration refinement algorithm},
journal={IMCIC 2010 - International Multi-Conference on Complexity, Informatics and Cybernetics, Proceedings},
year={2010},
volume={1},
pages={209-214},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032885734&partnerID=40&md5=440fe595b333a79deaeeddddd6f4735b},
abstract={Noise removal is an important task inside the image processing area. In this paper, an algorithm for reducing salt and pepper noise and improving the restoration quality through refinement is presented. This algorithm proposes a double screen. As a first step, the algorithm computes an estimation of the denoised image by using an adaptive median filter. Then, the Non-Local Means algorithm is used in order to have a better quality of reconstitution. Obtained results show that the implementation of this proposal gives considerable noise suppression, even with high noise densities, and it could prepare the image for other processes like image segmentation and object recognition.},
author_keywords={Adaptive median filter;  Image denoising;  Salt and pepper noise},
keywords={Adaptive filtering;  Adaptive filters;  Cybernetics;  Image processing;  Image segmentation;  Median filters;  Object recognition;  Restoration;  Salt removal, Adaptive median filter;  Noise removal;  Noise suppression;  Non local means;  Refinement algorithms;  Restoration quality;  Salt-and-pepper noise;  Salt-and-pepper noise removal, Image denoising},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Al-Khaffaf2009607,
author={Al-Khaffaf, H.S.M. and Zawawi Talib, A. and Abdul, R.},
title={Salt and pepper noise removal from document images},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2009},
volume={5857 LNCS},
pages={607-618},
doi={10.1007/978-3-642-05036-7_57},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-76649137310&doi=10.1007%2f978-3-642-05036-7_57&partnerID=40&md5=bc0fd1a3382e15528d2023f9e67b533c},
abstract={In this paper a noise removal algorithm is proposed by adding a procedure to enhance noise removal to a third party algorithm as a post processing step. The procedure (TAMD) has been proposed to enhance salt and pepper noise removal. TAMD analyzes thin line blobs before deciding to retain or remove them. It has been successfully applied previously in two noise removal algorithms by integrating their algorithm logic with the procedure. In this paper, a noise removal algorithm is proposed by utilizing it as a post processing step. The performance of the proposed noise removal algorithm is compared to many other algorithms including state of the art methods such as median and center weighted median. Real scanned images of mechanical engineering drawings corrupted by 20% salt and pepper noise are used in the experiment. Objective performance evaluation (PSNR and DRDM) has shown that our proposed noise removal algorithm is better than other studied algorithms. © 2009 Springer-Verlag.},
author_keywords={Line drawings;  Mechanical engineering drawings;  Noise removal;  Salt and pepper},
keywords={Center weighted medians;  Document images;  Line drawings;  Noise removal;  Noise removal algorithm;  Other algorithms;  Performance evaluation;  Post processing;  Salt-and-pepper noise;  Salt-and-pepper noise removal;  Scanned images;  State-of-the-art methods;  Third parties, Algorithms;  Mechanical engineering, Salt removal},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Li2009,
author={Li, W. and Sun, Y. and Chen, S.},
title={A new algorithm for removal of high-density salt and pepper noises},
journal={Proceedings of the 2009 2nd International Congress on Image and Signal Processing, CISP'09},
year={2009},
doi={10.1109/CISP.2009.5301350},
art_number={5301350},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-73849109382&doi=10.1109%2fCISP.2009.5301350&partnerID=40&md5=7412b404bde46527219b5655a41f0907},
abstract={To improve the performance of high-density salt and pepper noise denoising, a new detail preserving median filter algorithm is proposed in this paper. The method replaces only corrupted pixels by either the trimmed median or the average of previously processed neighborhood pixels, while uncorrupted pixels remain unchanged. Experimental results clearly show that the proposed algorithm outperforms many of the existing methods in terms of visual quality and quantitative measures. The advantage of the proposed method is that it works well for high-density salt & pepper noise even up to a noise density of 90%. ©2009 IEEE.},
author_keywords={Denoising;  Detail preserving;  High-density;  Median;  Salt & pepper},
keywords={De-noising;  Detail preserving;  Existing method;  High-density;  Median filter algorithms;  Noise density;  Pepper noise;  Quantitative measures;  Salt-and-pepper noise;  Visual qualities, Algorithms;  Pixels;  Signal processing, Salt removal},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Viswanathan20091374,
author={Viswanathan, K. and Ordentlich, E.},
title={Lower limits of discrete universal denoising},
journal={IEEE Transactions on Information Theory},
year={2009},
volume={55},
number={3},
pages={1374-1386},
doi={10.1109/TIT.2008.2011429},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-62749189893&doi=10.1109%2fTIT.2008.2011429&partnerID=40&md5=2bdc628f2219d0661c395143bc266db5},
abstract={In the spirit of results on universal compression, we compare the performance of universal denoisers on discrete memoryless channels to that of the best performance obtained by an omniscient κ th-order sliding-window denoiser, namely, one that is tuned to the transmitted noiseless sequence. We show that the additional loss incurred in the worst case by any universal denoiser on a length-n sequence grows at least like Ω(√n/ck), where c is a constant depending on the channel parameters and the loss function. This shows that for fixed κ the additional loss incurred by the Discrete Universal Denoiser (DUDE) is no larger than a constant multiplicative factor of the best possible. Furthermore, we compare universal denoisers to denoisers that are aware of the distribution of the transmitted noiseless sequence. We show that, even for this weaker target loss, for any universal denoiser there exists some distribution for the noiseless sequence corresponding to a sequence of independent and identically distributed (i.i.d.) random variables whose optimum expected loss is lower than that incurred by the universal denoiser by Ω(√n/ck). © 2009 IEEE.},
author_keywords={Compound Bayes;  Denoising;  Lower bounds;  Regret;  Universal},
keywords={Control theory;  Data compression;  Random variables, Compound Bayes;  Denoising;  Lower bounds;  Regret;  Universal, Communication channels (information theory)},
document_type={Article},
source={Scopus},
}

@ARTICLE{Al-Khaffaf2009689,
author={Al-Khaffaf, H.S.M. and Talib, A.Z. and Salam, R.A.},
title={Enhancing salt-and-pepper noise removal in binary images of engineering drawing},
journal={IEICE Transactions on Information and Systems},
year={2009},
volume={E92-D},
number={4},
pages={689-704},
doi={10.1587/transinf.E92.D.689},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-76649105984&doi=10.1587%2ftransinf.E92.D.689&partnerID=40&md5=c2135563423d2909c5042741f85f57c5},
abstract={Noise removal in engineering drawing is an important operation performed before other image analysis tasks. Many algorithms have been developed to remove salt-and-pepper noise from document images. Cleaning algorithms should remove noise while keeping the real part of the image unchanged. Some algorithms have disadvantages in cleaning operation that leads to removing of weak features such as short thin lines. Others leave the image with hairy noise attached to image objects. In this article a noise removal procedure called TrackAndMayDel (TAMD) is developed to enhance the noise removal of salt-and-pepper noise in binary images of engineering drawings. The procedure could be integrated with third party algorithms' logic to enhance their ability to remove noise by investigating the structure of pixels that are part of weak features. It can be integrated with other algorithms as a post-processing step to remove noise remaining in the image such as hairy noise attached with graphical elements. An algorithm is proposed by incorporating TAMD in a third party algorithm. Real scanned images from GREC'03 contest are used in the experiment. The images are corrupted by salt-and-pepper noise at 10%, 15%, and 20% levels. An objective performance measure that correlates with human vision as well as MSE and PSNR are used in this experiment. Performance evaluation of the introduced algorithm shows better-quality images compared to other algorithms. ©2009 The Institute of Electronics, Information and Communication Engineers.},
author_keywords={Binary image;  Document analysis and recognition;  Engineering drawing;  Impulsive noise;  Salt/pepper noise removal},
keywords={Binary images;  Bins;  Cleaning;  Image analysis;  Impulse noise;  Quality control;  Salt removal, Cleaning operations;  Document analysis;  Engineering drawing;  Graphical elements;  Noise removal;  Objective performance measures;  Salt-and-pepper noise;  Salt-and-pepper noise removal, Image denoising},
document_type={Article},
source={Scopus},
}

@ARTICLE{Liu200748,
author={Liu, P. and Wang, J.-Y. and Yin, Z.-K.},
title={Removal of salt- and-pepper noises from images by linear prediction},
journal={Tiedao Xuebao/Journal of the China Railway Society},
year={2007},
volume={29},
number={6},
pages={48-51},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-38049121176&partnerID=40&md5=a6c76b71e59ab75b6d3b2a30b236a108},
abstract={To remove salt- and-pepper noises from an image, an algorithm is proposed on the basis of linear prediction. Each pixel is estimated to be a signal pixel or possible noise pixel according to characteristics of the salt- and-pepper noise. Linear prediction is employed to the possible noise pixels, which are then replaced by the predicted values, while the signal pixels are kept untouched to preserve the detail of the image. Experimental results prove that the presented method has less calculation and shows strong denoising ability, especially for highly corrupted images.},
author_keywords={Image denoising;  Image processing;  Linear prediction;  Salt- and-pepper noise},
keywords={Algorithms;  Calculations;  Forecasting, Image denoising;  Linear prediction;  Salt and pepper noise, Image processing},
document_type={Article},
source={Scopus},
}

@ARTICLE{Song2007474,
author={Song, Y. and Li, M.-T. and Sun, L.-N.},
title={Image salt and pepper noise self-adaptive suppression algorithm based on similarity function},
journal={Zidonghua Xuebao/Acta Automatica Sinica},
year={2007},
volume={33},
number={5},
pages={474-479},
doi={10.1360/aas-007-0474},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-34250376899&doi=10.1360%2faas-007-0474&partnerID=40&md5=97c32acf1d46d04d27183cb70aa2090e},
abstract={Through summarizing the existing detail-preserving salt and pepper noise suppression methods, a new similarity function self-adaptive weighted algorithm is proposed. It analyzes and overcomes the shortcoming of the local extremum misjudgment of the Maximum-minimum noise detector by using a similarity function self-adaptive weighted algorithm. The local window noise probability is estimated by applying extremum trimming operation to select a suitable filtering window (recursive window or non-recursive window). Thus the proposed algorithm realizes self-adaptive suppression of different salt and pepper noise probabilities using a 3 × 3 filtering window. Experiments show that the results of salt and pepper noise suppression, detail-preserving and computation efficiency are satisfactory.},
author_keywords={Detail-preserving;  Extremum trimming operation;  Salt and pepper noise detector;  Similarity function},
keywords={Algorithms;  Computational efficiency;  Functions;  Image processing;  Probability;  Signal filtering and prediction;  Signal processing;  Spurious signal noise, Detail preserving;  Extremum trimming operation;  Filtering windows;  Noise probability;  Noise suppression;  Recursive windows;  Salt and pepper noise detectors;  Similarity functions, Image quality},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Viswanathan20062363,
author={Viswanathan, K. and Ordentlich, E.},
title={Lower limits of discrete universal denoising},
journal={IEEE International Symposium on Information Theory - Proceedings},
year={2006},
pages={2363-2367},
doi={10.1109/ISIT.2006.262011},
art_number={4036393},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-39049087133&doi=10.1109%2fISIT.2006.262011&partnerID=40&md5=c3cdf3a5c7a0c2d20213f35a9504cc44},
abstract={Following recent work by Weissman et al, in the spirit of results on universal compression, we compare the performance of universal denoisers on discrete memoryless channels to that of the best k-th order omniscient denoiser, namely one that is tuned to the transmitted noiseless sequence. We show that the additional loss incurred in the worst case by any denoiser on a length-n sequence grows like Ω(ck/√n), where c &gt; 1 is a constant depending on the channel parameters and the loss function. This shows that for fixed k, the additional loss incurred by the Discrete Universal Denoiser (DUDE) is no larger than a constant multiplicative factor of the best possible. © 2006 IEEE.},
keywords={Discrete Universal Denoiser (DUDE);  Transmitted noiseless sequence;  Universal denoising, Parameter estimation;  Storage allocation (computer), Channel coding},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Gemelos20063476,
author={Gemelos, G.M. and Sigurjónsson, S. and Weissman, T.},
title={Universal minimax discrete denoising under channel uncertainty},
journal={IEEE Transactions on Information Theory},
year={2006},
volume={52},
number={8},
pages={3476-3497},
doi={10.1109/TIT.2006.878234},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33746635187&doi=10.1109%2fTIT.2006.878234&partnerID=40&md5=e776ac4ee20c8261576b32dfde5872ec},
abstract={The goal of a denoising algorithm is to recover a signal from its noise-corrupted observations. Perfect recovery is seldom possible and performance is measured under a given single-letter fidelity criterion. For discrete signals corrupted by a known discrete memoryless channel (DMC), the Discrete Universal DEnoiser (DUDE) was recently shown to perform this task asymptotically optimally, without knowledge of the statistical properties of the source. In the present work, we address the scenario where, in addition to the lack of knowledge of the source statistics, there is also uncertainty in the channel characteristics. We propose a family of discrete denoisers and establish their asymptotic optimality under a minimax performance criterion which we argue is appropriate for this setting. As we show elsewhere, the proposed schemes can also be implemented computationally efficiently. © 2006 IEEE.},
author_keywords={Denoising;  Denoising algorithms;  Discrete Universal DEnoiser (DUDE);  Discrete universal denoising;  Estimation;  Minimax schemes},
keywords={Algorithms;  Estimation;  Optimal systems;  Optimization;  Spurious signal noise, Denoising;  Denoising algorithms;  Discrete universal denoising;  Minimax schemes, Communication channels (information theory)},
document_type={Article},
source={Scopus},
}

@ARTICLE{Gemelos20062263,
author={Gemelos, G.M. and Sigurjónsson, S. and Weissman, T.},
title={Algorithms for discrete denoising under channel uncertainty},
journal={IEEE Transactions on Signal Processing},
year={2006},
volume={54},
number={6 I},
pages={2263-2276},
doi={10.1109/TSP.2006.874295},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33744528860&doi=10.1109%2fTSP.2006.874295&partnerID=40&md5=0beb7d729b9123ca0ceb2e6d046ce315},
abstract={The goal of a denoising algorithm is to reconstruct a signal from its noise-corrupted observations. Perfect reconstruction is seldom possible and performance is measured under a given fidelity criterion. In a recent work, the authors addressed the problem of denoising unknown discrete signals corrupted by a discrete memoryless channel when the channel, rather than being completely known, is only known to lie in some uncertainty set of possible channels. A sequence of denoisers was derived for this case and shown to be asymptotically optimal with respect to a worst-case criterion argued most relevant to this setting. In the present paper, we address the implementation and complexity of this denoiser for channels parametrized by a scalar, establishing its practicality. We show that for symmetric channels, the problem can be mapped into a convex optimization problem, which can be solved efficiently. We also present empirical results suggesting the potential of these schemes to do well in practice. A key component of our schemes is an estimator of the subset of channels in the uncertainty set that are feasible in the sense of being able to give rise to the noise-corrupted signal statistics for some channel input distribution. We establish the efficiency of this estimator, both algorithmically and experimentally. We also present a modification of the recently developed discrete universal denoiser (DUDE) that assumes a channel based on the said estimator, and show that, in practice, the resulting scheme performs well. For concreteness, we focus on the binary alphabet case and binary symmetric channels, but also discuss the extensions of the algorithms to general finite alphabets and to general channels parameterized by a scalar. © 2006 IEEE.},
author_keywords={Binary images;  Channel uncertainty;  Convex optimization;  Denoising algorithms;  Discrete universal denoiser (DUDE);  Discrete universal denoising;  Image denoising;  Minimax schemes},
keywords={Algorithms;  Asymptotic stability;  Communication channels (information theory);  Image analysis;  Optimization;  Parameter estimation;  Signal noise measurement;  Signal reconstruction, Binary images;  Channel uncertainty;  Convex optimization;  Denoising algorithms;  Discrete universal denoising;  Image denoising;  Minimax schemes, Spurious signal noise},
document_type={Article},
source={Scopus},
}


@INPROCEEDINGS{morph-denoising,
  author={Jamil, N. and Sembok, T. Mohd Tengku and Bakar, Z. A.},
  booktitle={2008 International Symposium on Information Technology}, 
  title={Noise removal and enhancement of binary images using morphological operations}, 
  year={2008},
  volume={4},
  number={},
  pages={1-6},
  doi={10.1109/ITSIM.2008.4631954}}
  
  
@article{deep-denoising,
title = {Deep learning on image denoising: An overview},
journal = {Neural Networks},
volume = {131},
pages = {251-275},
year = {2020},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2020.07.025},
url = {https://www.sciencedirect.com/science/article/pii/S0893608020302665},
author = {Chunwei Tian and Lunke Fei and Wenxian Zheng and Yong Xu and Wangmeng Zuo and Chia-Wen Lin},
keywords = {Deep learning, Image denoising, Real noisy images, Blind denoising, Hybrid noisy images},
abstract = {Deep learning techniques have received much attention in the area of image denoising. However, there are substantial differences in the various types of deep learning methods dealing with image denoising. Specifically, discriminative learning based on deep learning can ably address the issue of Gaussian noise. Optimization models based on deep learning are effective in estimating the real noise. However, there has thus far been little related research to summarize the different deep learning techniques for image denoising. In this paper, we offer a comparative study of deep techniques in image denoising. We first classify the deep convolutional neural networks (CNNs) for additive white noisy images; the deep CNNs for real noisy images; the deep CNNs for blind denoising and the deep CNNs for hybrid noisy images, which represents the combination of noisy, blurred and low-resolution images. Then, we analyze the motivations and principles of the different types of deep learning methods. Next, we compare the state-of-the-art methods on public denoising datasets in terms of quantitative and qualitative analyses. Finally, we point out some potential challenges and directions of future research.}
}
  

@ARTICLE{Liang20061534,
author={Liang, X. and Asano, T.},
title={A linear time algorithm for binary fingerprint image denoising using distance transform},
journal={IEICE Transactions on Information and Systems},
year={2006},
volume={E89-D},
number={4},
pages={1534-1542},
doi={10.1093/ietisy/e89-d.4.1534},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33646245653&doi=10.1093%2fietisy%2fe89-d.4.1534&partnerID=40&md5=c3419ed6eee38cd7467218c45be64a8d},
abstract={Fingerprints are useful for biometric purposes because of their well known properties of distinctiveness and persistence over time. However, owing to skin conditions or incorrect finger pressure, original fingerprint images always contain noise. Especially, some of them contain useless components, which are often mistaken for the terminations that are an essential minutia of a fingerprint. Mathematical Morphology (MM) is a powerful tool in image processing. In this paper, we propose a linear time algorithm to eliminate impulsive noise and useless components, which employs generalized and ordinary morphological operators based on Euclidean distance transform. There are two contributions. The first is the simple and efficient MM method to eliminate impulsive noise, which can be restricted to a minimum number of pixels. We know the performance of MM is heavily dependent on structuring elements (SEs), but finding an optimal SE is a difficult and nontrivial task. So the second contribution is providing an automatic approach without any experiential parameter for choosing appropriate SEs to eliminate useless components. We have developed a novel algorithm for the binarization of fingerprint images [1]. The information of distance transform values can be obtained directly from the binarization phase. The results show that using this method on fingerprint images with impulsive noise and useless components is faster than existing denoising methods and achieves better quality than earlier methods. Copyright © 2006 The Institute of Electronics, Information and Communication Engineers.},
author_keywords={Euclidean distance transform;  Impulsive noise;  Integral image;  Mathematical morphology (MM);  Useless components},
keywords={Image analysis;  Impulse noise;  Integral equations;  Learning systems;  Mathematical models;  Mathematical morphology;  Algorithms;  Cosine transforms;  Pattern recognition, Euclidean distance transform;  Integral image;  Linear time algorithms;  Useless components, Pattern recognition systems;  Image processing},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Giurcǎneanu20051275,
author={Giurcǎneanu, C.D. and Yu, B.},
title={Efficient algorithms for discrete universal denoising for channels with memory},
journal={IEEE International Symposium on Information Theory - Proceedings},
year={2005},
volume={2005},
pages={1275-1279},
doi={10.1109/ISIT.2005.1523547},
art_number={1523547},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-33749446700&doi=10.1109%2fISIT.2005.1523547&partnerID=40&md5=761ea10d956364e69889a6d6dd973b92},
abstract={The paper is focused on the problem of discrete universal denoising: one estimates the input sequence to a discrete channel based on the observation of the entire output signal, and without assuming any particular knowledge on the statistical properties of the input sequence. A 2k + 1 sliding window denoiser (DUDE) has recently been introduced, and its asymptotic optimality was proven in the case of memoryless channels and additive channels with memory. However, DUDE is computationally infeasible for large values of its context parameter k. The purpose of this paper is to further investigate DUDE in the case of channels with memory. First, for the important family of binary additive channels, we propose H-DUDE, a computationally feasible implementation of DUDE. It modifies the DUDE algorithm to exploit the property of the block transition probability matrix to be diagonalized by the Hadamard transform. H-DUDE accommodates large values of k, and we demonstrate this for the particular case of the finite-memory contagion channel. Second, we apply DUDE for a non-additive channel model that was previously used in design of stack filters to show its favorable performance.},
keywords={Block transition probability matrix;  Discrete universal denoising;  Non-additive channel model, Algorithms;  Computational complexity;  Data storage equipment;  Mathematical models;  Mathematical transformations;  Statistical methods, Information theory},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Weissman20055,
author={Weissman, T. and Ordentlich, E. and Seroussi, G. and Sergio, V. and Weinberger, M.J.},
title={Universal discrete denoising: Known channel},
journal={IEEE Transactions on Information Theory},
year={2005},
volume={51},
number={1},
pages={5-28},
doi={10.1109/TIT.2004.839518},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-12444304529&doi=10.1109%2fTIT.2004.839518&partnerID=40&md5=e90a2cd9fb7fc504acc85d8d2e2cf3be},
abstract={A discrete denoising algorithm estimates the input sequence to a discrete memoryless channel (DMC) based on the observation of the entire output sequence. For the case in which the DMC is known and the quality of the reconstruction is evaluated with a given single-letter fidelity criterion, we propose a discrete denoising algorithm that does not assume knowledge of statistical properties of the input sequence. Yet, the algorithm is universal in the sense of asymptotically performing as well as the optimum denoiser that knows the input sequence distribution, which is only assumed to be stationary. Moreover, the algorithm is universal also in a semi-stochastic setting, in which the input is an individual sequence, and the randomness is due solely to the channel noise. The proposed denoising algorithm is practical, requiring a linear number of register-level operations and sublinear working storage size relative to the input data length. © 2005 IEEE.},
author_keywords={Context models;  Denoising;  Discrete filtering;  Discrete memoryless channels (DMCs);  Individual sequences;  Noisy channels;  Universal algorithms},
keywords={Algorithms;  Communication channels (information theory);  Mathematical models;  Probability;  Random processes;  Signal reconstruction;  Spurious signal noise;  Theorem proving, Context models;  Discrete denoising algorithm;  Discrete filtering;  Discrete memoryless channel (DMC);  Noisy channels;  Universal discrete denoising, Signal filtering and prediction},
document_type={Article},
source={Scopus},
}

@CONFERENCE{Gemelos2004997,
author={Gemelos, G. and Sigurjónsson, S. and Weissman, T.},
title={Universal minimax binary image denoising under channel uncertainty},
journal={Proceedings - International Conference on Image Processing, ICIP},
year={2004},
volume={5},
pages={997-1000},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-12444312164&partnerID=40&md5=0aef55a91c419597c236e5125c1a9c98},
abstract={We consider the problem of denoising a binary image corrupted by a noisy medium which flips each component in the original image, independently, to its complementary value with some fixed but unknown probability δ < 1/2. We propose a denoiser which assumes no knowledge of statistical properties of the image, yet asymptotically attains the performance of the scheme that knows the noisy image statistics and operates optimally in a minimax sense. The proposed scheme is implementable, with complexity linear in the image size. Preliminary experimental results are presented which indicate that the scheme has the potential to do well on real data. © 2004 IEEE.},
keywords={Binary images;  Binary symmetric channel (BSC);  Channel uncertainty;  Noise distribution uncertainty, Computational complexity;  Database systems;  Image reconstruction;  Problem solving;  Spurious signal noise;  Statistical methods, Image analysis},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Liang2004309,
author={Liang, X. and Asano, T.},
title={A fast denoising method for binary fingerprint image},
journal={Proceedings of the Fourth IASTED International Conference on Visualization, Imaging, and Image Processing},
year={2004},
pages={309-313},
art_number={452-168},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-11144290658&partnerID=40&md5=7de977296cba7f7fcf5eb651a4495d4e},
abstract={In this paper we propose a fast method for binary finger-print image denoising that employs the generalized and ordinary morphological operators based on Euclidian distance transform. This method avoids quite a number of computational redundance. In particular, the computations of denosing step are restricted to a minimum number of pixels. The results show that applying this method on fingerprint image with impulsive noise and useless components yields a segmentation much closer to that of an expect for extracting the minutia accurately.},
author_keywords={Euclidean distance transform;  Generalized morphological operator (GMO);  Ordinary morphological operator (OMO);  Strictness;  Structuring element (SE);  Useless component},
keywords={Algorithms;  Image segmentation;  Mathematical operators;  Mathematical transformations;  Set theory;  Skin, Euclidean distance transforms;  Generalized morphological operators (GMO);  Ordnary morphological operators (OMO);  Strictness;  Structuring elements (SE);  Useless components, Object recognition},
document_type={Conference Paper},
source={Scopus},
}

@ARTICLE{Abdel-Dayem2004191,
author={Abdel-Dayem, A.R. and Hamou, A.K. and El-Sakka, M.R.},
title={Novel Adaptive Filtering for Salt-and-Pepper Noise Removal from Binary Document Images},
journal={Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
year={2004},
volume={3212},
pages={191-199},
doi={10.1007/978-3-540-30126-4_24},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-35048853614&doi=10.1007%2f978-3-540-30126-4_24&partnerID=40&md5=4a5136be73d9343232ba4563a86ff08f},
abstract={Noise removal from binary document and graphic images plays a vital role in the success of various applications. These applications include optical character recognition, content-based image retrieval and hand-written recognition systems. In this paper, we present a novel adaptive scheme for noise removal from binary images. The proposed scheme is based on connected component analysis. Simulations over a set of binary images corrupted by 5%, 10% and 15% salt-and-pepper noise showed that this technique reduces the presence of this noise, while preserving fine thread lines that may be removed by other techniques (such as median and morphological filters). © Springer-Verlag 2004.},
keywords={Adaptive optics;  Binary images;  Bins;  Character recognition;  Content based retrieval;  Image retrieval;  Information retrieval systems;  Median filters;  Optical character recognition;  Salt removal;  Search engines, Adaptive scheme;  Binary document image;  Connected component analysis;  Content based image retrieval;  Morphological filters;  Recognition systems;  Salt-and-pepper noise;  Salt-and-pepper noise removal, Image denoising},
document_type={Article},
source={Scopus},
}

@inproceedings{dude-bin,
author={Ordentlich, E. and Seroussi, G. and Verdú, S. and Weinberger, M. and Weissman, T.},
title={A discrete universal denoiser and its application to binary images},
booktitle={IEEE Intl. Conf. on Image Proc.},
year={2003},
volume={1},
pages={117-120},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-0344666676&partnerID=40&md5=0391d487a629914c04545fbc53705a45},
abstract={In a recent work, the authors introduced a discrete universal denoiser (DUDE) for recovering a signal with finite-valued components corrupted by finite-valued, uncorrelated noise. The DUDE is asymptotically optimal and universal, in the sense of asymptotically achieving, without access to any information on the statistics of the clean signal, the same performance as the best denoiser that does have access to such information. It is also practical, and can be implemented in low complexity. In this work, we extend the definition of the DUDE to two-dimensionally indexed data, and present results of an implementation of the scheme for binary images. Section 2 presents the problem setting, definitions, and notation used throughout the paper. Section 3 describes the DUDE for two-dimensional data (this description readily extends to higher dimensions). Section 4 presents theoretical performance guarantees establishing the DUDE's asymptotic optimality. The denoiser assumes a particularly simple form for binary alphabets, which is presented in Section 5. Practical considerations in the implementation of the binary scheme are presented in Section 6, while experimental results of its application to noisy binary images are presented in Section 7, In the examples considered we find that the DUDE outperforms current popular schemes for binary image denosing. Finally, in Section 8 we discuss conclusions and directions for ongoing and future research.},
keywords={Asymptotic stability;  Binary sequences;  Database systems;  Heuristic methods;  Indexing (of information);  Theorem proving, Binary images;  Denoisers, Image analysis},
document_type={Conference Paper},
source={Scopus},
}

@inproceedings{dude,
author={Weissman, T. and Ordentlich, E. and Seroussi, G. and Verdú, S. and Weinberger, M.},
title={Universal discrete denoising: Known channel},
booktitle={IEEE International Symposium on Information Theory - Proceedings},
year={2003},
pages={84},
doi={10.1109/isit.2003.1228098},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-0142008488&doi=10.1109%2fisit.2003.1228098&partnerID=40&md5=430cafc26b6f7b2a92a6782b357fd471},
keywords={Algorithms;  Communication channels (information theory);  Computational complexity;  Conformal mapping;  Decoding;  Matrix algebra;  Probability distributions;  Random processes;  Signal distortion;  Signal encoding;  Vectors, Channel coding;  Denoising;  Discrete memoryless channel;  Discrete universal denoiser, Signal filtering and prediction},
document_type={Conference Paper},
source={Scopus},
}

@CONFERENCE{Park198853,
author={Park, R.H. and Jung, G.S.},
title={A Fast Noise Reduction Technique Of Binary Images From An Image Scanner},
journal={Proceedings of SPIE - The International Society for Optical Engineering},
year={1988},
volume={1001},
pages={53-60},
doi={10.1117/12.968937},
url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957466014&doi=10.1117%2f12.968937&partnerID=40&md5=4be04b3ac90222c47c8550c78f6436ba},
abstract={Binary image sometimes shows the random noisy dots and blobs, which are independent of the input data, depending on the illumination condition of the input data and characteristic of an image scanner itself. We propose the binary image enhancement algorithm that smooths out the noise element while preserving thin contours. The proposed algorithm is fast enough to be applicable to nearly real-time services. Computer simulation shows that the proposed method gives better performance than the existing methods in terms of the computational complexity and the effectiveness of the noise reduction with preserving thin contours. It also increases the data compression ratio of the image data based on the G4 facsimile encoding schemes. © 1988, SPIE.},
keywords={Data compression ratio;  Image denoising;  Image enhancement;  Information services;  Input output programs;  Noise abatement;  Scanning;  Visual communication, Encoding schemes;  Illumination conditions;  Image data;  Image enhancement algorithm;  Image scanner;  Input datas;  Noise reduction technique;  Real time service, Binary images},
document_type={Conference Paper},
source={Scopus},
}

@article{deep-learning,
    title   = {{An Analysis and Implementation of the FFDNet Image Denoising Method}},
    author  = {Tassano, M. and Delon, J. and Veit, T.},
    journal = {{Image Processing On Line}},
    volume  = {9},
    pages   = {1--25},
    year    = {2019},
    note    = {\url{https://doi.org/10.5201/ipol.2019.231}}
}


@article{fast-nlm,
author = {S. Ghosh and K.~N. Chaudhury},
title = {{Fast separable nonlocal means}},
volume = {25},
journal = {Journal of Electronic Imaging},
number = {2},
publisher = {SPIE},
pages = {1 -- 14},
abstract = {We propose a simple and fast algorithm called PatchLift for computing distances between patches (contiguous block of samples) extracted from a given one-dimensional signal. PatchLift is based on the observation that the patch distances can be efficiently computed from a matrix that is derived from the one-dimensional signal using lifting; importantly, the number of operations required to compute the patch distances using this approach does not scale with the patch length. We next demonstrate how PatchLift can be used for patch-based denoising of images corrupted with Gaussian noise. In particular, we propose a separable formulation of the classical nonlocal means (NLM) algorithm that can be implemented using PatchLift. We demonstrate that the PatchLift-based implementation of separable NLM is a few orders faster than standard NLM and is competitive with existing fast implementations of NLM. Moreover, its denoising performance is shown to be consistently superior to that of NLM and some of its variants, both in terms of peak signal-to-noise ratio/structural similarity index and visual quality.},
keywords = {nonlocal means, denoising, patch distance, fast algorithm, separable filtering, lifting, Denoising, Chromium, Image filtering, Image processing, Gaussian filters, Nonlinear filtering, Visualization, Electronic filtering, Convolution, Image denoising},
year = {2016},
doi = {10.1117/1.JEI.25.2.023026},
URL = {https://doi.org/10.1117/1.JEI.25.2.023026}
}

@INPROCEEDINGS{entropy-filter,  author={J. Zuo and C. Zhao and Q. Pan and W. Lian},  booktitle={2006 6th World Congress on Intelligent Control and Automation},   title={A Novel Binary Image Filtering Algorithm Based on Information Entropy},   year={2006},  volume={2},  number={},  pages={10375-10379},  doi={10.1109/WCICA.2006.1714035}}


@article{lambda-filter,
author = {Li, Li and Ge, H. and Zhang, Y. and Gao, J.},
title = {Low-Density Noise Removal Based on Lambda Multi-Diagonal Matrix Filter for Binary Image},
year = {2018},
issue_date = {March 2018},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
volume = {29},
number = {6},
issn = {0941-0643},
url = {https://doi.org/10.1007/s00521-016-2538-7},
doi = {10.1007/s00521-016-2538-7},
abstract = {Binary image denoising is a well-known problem, and it is the concern of diverse application areas. Many classical denoising techniques have evolved over the years, such as mean filter, median filter, and morphological filter. A new denoising method based on the multiplication of lambda multi-diagonal binary matrix ($$lambda $$\'{z}-MDBM) is proposed for binary images in this paper. In proposed method, first the users need to choose an appropriate lambda value from the set $${lambda |lambda in [0.5,1]}$${\'{z}|\'{z}\'{z}[0.5,1]}, and then the hybrid noisy binary image matrix can be obtained by adding the noisy binary image matrix times the $$lambda $$\'{z}-MDBM and the transpose of the noisy binary image matrix times the $$lambda $$\'{z}-MDBM, and finally the de-noised binary image can be obtained by a preset threshold. The experimental results show that a new denoising method based on $$lambda $$\'{z}-MDBM is possible in peak signal-to-noise ratio and mean square error.},
journal = {Neural Comput. Appl.},
month = {mar},
pages = {173–185},
numpages = {13},
keywords = {Lambda multi-diagonal matrix filter, Binary image processing, Image denoising, Filtering}
}

@book{morph,
title={Morphological Image Analysis},
author={P. Soille},
publisher={Springer-Verlag, Berlin-Heidelberg},
year={2004},
isbn={978-3-662-05088-0},
doi={https://doi.org/10.1007/978-3-662-05088-0},
edition={2}
}